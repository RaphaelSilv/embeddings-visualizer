{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06 - JANELA - GerarComparacaoEntrePalavras_COHEBERTMANUAL_v1.ipynb","provenance":[{"file_id":"1ZQvuAVwA3IjybezQOXnrXMGAnMyZRuPU","timestamp":1585340447636},{"file_id":"1FsBCkREOaDopLF3PIYUuQxLR8wRfjQY1","timestamp":1559844903389},{"file_id":"1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y","timestamp":1554843110227}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4039fe4566054bb79de440bb1bc00b3d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c43765dc21c84e7e9ebea0099460b2ed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d099f97dfaf54cd8bf693dfdc882d728","IPY_MODEL_db92cc2a006f4a5ab7fbcedcbad2454d","IPY_MODEL_ff752d3ac84d40b18de90fbb73c4f4e0"]}},"c43765dc21c84e7e9ebea0099460b2ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d099f97dfaf54cd8bf693dfdc882d728":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e77a838139849f18bcfdd785d3a6f67","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_caee92a77bf5484c84c93e229ed08046"}},"db92cc2a006f4a5ab7fbcedcbad2454d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4dd929f0af5e4dc4b4700d8fa13e9288","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":577393393,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":577393393,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9ada8986b0704ea5b47f564f2212f7c6"}},"ff752d3ac84d40b18de90fbb73c4f4e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6ab282f630244f7cbceba9aa5e7539ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 577M/577M [00:48&lt;00:00, 9.96MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9b17ad94aeb49fdb279fc190e48d981"}},"3e77a838139849f18bcfdd785d3a6f67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"caee92a77bf5484c84c93e229ed08046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4dd929f0af5e4dc4b4700d8fa13e9288":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9ada8986b0704ea5b47f564f2212f7c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ab282f630244f7cbceba9aa5e7539ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b9b17ad94aeb49fdb279fc190e48d981":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30bbb442dd12432598ea3291a57849af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fdf7d69e13d04141a958fd67f4a412b9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_078af941f7454cb480181364c5e8e824","IPY_MODEL_6f45afe417df4e2cb1fc0ad9d44ebb89","IPY_MODEL_4cc5be02ecd64b16b06ad34cbf5019b5"]}},"fdf7d69e13d04141a958fd67f4a412b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"078af941f7454cb480181364c5e8e824":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c1055c2660a43ed9f81228547d1325b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07a347a3dd9041c4912470b47fd03822"}},"6f45afe417df4e2cb1fc0ad9d44ebb89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_59c0b4628c944a74a1a82682eec94022","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1244275810,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1244275810,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d888666150ce497894afeafde24523cc"}},"4cc5be02ecd64b16b06ad34cbf5019b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_51a5281c94504939a964a618089a54c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.24G/1.24G [01:29&lt;00:00, 15.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2d901edced3f4ea09475e6e9910ea5ec"}},"4c1055c2660a43ed9f81228547d1325b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07a347a3dd9041c4912470b47fd03822":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59c0b4628c944a74a1a82682eec94022":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d888666150ce497894afeafde24523cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51a5281c94504939a964a618089a54c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2d901edced3f4ea09475e6e9910ea5ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4423d840de548899b9dfeb6196e64ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a58b95cf9b04fcbadb863e87b4641d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_221bfd6dc918419d995780d5d546399b","IPY_MODEL_bd394692954044f394b328910c7a65a2","IPY_MODEL_75586a3711374bd48aa63283a94b8127"]}},"8a58b95cf9b04fcbadb863e87b4641d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"221bfd6dc918419d995780d5d546399b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8daef25e62474a02a660feab87cacd00","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4336a06ff334cb186956f876a693a5e"}},"bd394692954044f394b328910c7a65a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_33e3992279ab45c8a710b9892ed68678","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":209528,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":209528,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7550c307349c4885b2b796f347f5230f"}},"75586a3711374bd48aa63283a94b8127":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_47c330de6a9047eebf966d6e211f9b27","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 210k/210k [00:00&lt;00:00, 281kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b877e2f9cf5494bbb7a762499bb98b3"}},"8daef25e62474a02a660feab87cacd00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4336a06ff334cb186956f876a693a5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33e3992279ab45c8a710b9892ed68678":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7550c307349c4885b2b796f347f5230f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47c330de6a9047eebf966d6e211f9b27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7b877e2f9cf5494bbb7a762499bb98b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35a4c444a1154e11953b59e989f05b99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4b27342020ed4735b03414689b74c5f7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b6212d07aeb94cd38dc66486fd8385d5","IPY_MODEL_f49820b508544287aff69e4a190576c2","IPY_MODEL_e8d7cd36564b48af9b07bec63555affd"]}},"4b27342020ed4735b03414689b74c5f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6212d07aeb94cd38dc66486fd8385d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9379761406fb48ffb2b3243170551076","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Documentos: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d01a9ffc4e434c86ad4c15a0abff57d8"}},"f49820b508544287aff69e4a190576c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8981f1d005894e07a08a939fb8e8d359","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":40,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":40,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_377ce39479584fceaef05add9f6b2b9d"}},"e8d7cd36564b48af9b07bec63555affd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1ef3c3c2912242e59a57590b9214f1ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 40/40 [00:53&lt;00:00,  1.34s/ documento]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97e68fe0744c4b55a92c4ba8bbce6d41"}},"9379761406fb48ffb2b3243170551076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d01a9ffc4e434c86ad4c15a0abff57d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8981f1d005894e07a08a939fb8e8d359":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"377ce39479584fceaef05add9f6b2b9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ef3c3c2912242e59a57590b9214f1ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"97e68fe0744c4b55a92c4ba8bbce6d41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"EKOTlwcmxmej"},"source":["# Gerar comparação entre palavras dos documentos originais das sentenças do Cohebert manual\n","\n","Gera a comparação entre as palavras das sentenças dos documentos do conjunto de dados Cohebert manual utilizando os arquivos:\n","- `original.zip`\n","- `originalpos.zip`\n","\n","Cria o arquivo `comparacao_palavra_pX_kY.zip` com as comparações entre as palavras do documento, onde X é o número de documentos perturbados e Y o valor de top K predições.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OP33KWAtBMWs"},"source":["# 1 Preparação do ambiente\n","\n","Preparação do ambiente para execução do script."]},{"cell_type":"markdown","metadata":{"id":"PKUr9Vk4BNLC"},"source":["## 1.1 Tempo inicial de processamento"]},{"cell_type":"code","metadata":{"id":"JXclHCRQBSF2"},"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","# Marca o tempo de início do processamento\n","inicioProcessamento = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOcN8hK-scnt"},"source":["## 1.2 Funções e classes auxiliares"]},{"cell_type":"markdown","source":["Verifica se existe o diretório cohebert no diretório corrente.   \n"],"metadata":{"id":"OPRnA-mk5-c4"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import os # Biblioteca para manipular arquivos\n","\n","# ============================  \n","def verificaDiretorioCoheBERT():\n","    \"\"\"\n","      Verifica se existe o diretório cohebert no diretório corrente.    \n","    \"\"\"\n","    \n","    # Verifica se o diretório existe\n","    if not os.path.exists(DIRETORIO_COHEBERT):  \n","        # Cria o diretório\n","        os.makedirs(DIRETORIO_COHEBERT)\n","        logging.info(\"Diretório Cohebert criado: {}\".format(DIRETORIO_COHEBERT))\n","    \n","    return DIRETORIO_COHEBERT"],"metadata":{"id":"Fj5TaAH_5-nB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Realiza o download e um arquivo"],"metadata":{"id":"yDCOeh2y5jOH"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import requests # Biblioteca de download\n","from tqdm.notebook import tqdm as tqdm_notebook # Biblioteca para barra de progresso\n","\n","def downloadArquivo(url_arquivo, nome_arquivo_destino):\n","    \"\"\"    \n","      Realiza o download de um arquivo de uma url em salva em nome_arquivo_destino.\n","    \n","      Parâmetros:\n","        `url_arquivo` - URL do arquivo a ser feito download.      \n","        `nome_arquivo_destino` - Nome do arquivo a ser salvo.      \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Realiza o download de um arquivo em uma url\n","    data = requests.get(url_arquivo, stream=True)\n","    \n","    # Verifica se o arquivo existe\n","    if data.status_code != 200:\n","        logging.info(\"Exceção ao tentar realizar download {}. Response {}.\".format(url_arquivo, data.status_code))\n","        data.raise_for_status()\n","        return\n","\n","    # Recupera o nome do arquivo a ser realizado o download    \n","    nome_arquivo = nome_arquivo_destino.split(\"/\")[-1]  \n","\n","    # Define o nome e caminho do arquivo temporário    \n","    nome_arquivo_temporario = DIRETORIO_COHEBERT + \"/\" + nome_arquivo + \"_part\"\n","    \n","    logging.info(\"Download do arquivo: {}.\".format(nome_arquivo_destino))\n","    \n","    # Baixa o arquivo\n","    with open(nome_arquivo_temporario, \"wb\") as arquivo_binario:        \n","        tamanho_conteudo = data.headers.get(\"Content-Length\")        \n","        total = int(tamanho_conteudo) if tamanho_conteudo is not None else None\n","        # Barra de progresso de download\n","        progresso_bar = tqdm_notebook(unit=\"B\", total=total, unit_scale=True)                \n","        # Atualiza a barra de progresso\n","        for chunk in data.iter_content(chunk_size=1024):        \n","            if chunk:                \n","                progresso_bar.update(len(chunk))\n","                arquivo_binario.write(chunk)\n","    \n","    # Renomeia o arquivo temporário para o arquivo definitivo\n","    os.rename(nome_arquivo_temporario, nome_arquivo_destino)\n","    \n","    # Fecha a barra de progresso.\n","    progresso_bar.close()"],"metadata":{"id":"5B1mvfAU5jZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksYnRk7zLGp0"},"source":["Remove tags de um documento"]},{"cell_type":"code","metadata":{"id":"6qwKjGvyLG4v"},"source":["def remove_tags(documento):\n","    \"\"\"\n","      Remove tags de um documento\n","    \"\"\"\n","    \n","    import re\n","\n","    documentoLimpo = re.compile(\"<.*?>\")\n","    return re.sub(documentoLimpo, \"\", documento)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pduTsINLeaz"},"source":["Funções auxiliares de arquivos"]},{"cell_type":"code","metadata":{"id":"jirIzIstLea0"},"source":["def carregar(nomeArquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como um único parágrafo(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.  \n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nomeArquivo, \"r\", encoding= encoding)\n","    \n","    paragrafo = \"\"\n","    for linha in arquivo:\n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        # Remove as tags existentes no final das linhas\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          paragrafo = paragrafo + linha.strip() + \" \"\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    # Remove os espaços em branco antes e depois do parágrafo\n","    return paragrafo.strip()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def carregarLista(nomeArquivo, encoding=\"Windows-1252\"):\n","    \"\"\"\n","      Carrega um arquivo texto e retorna as linhas como uma lista de sentenças(texto).\n","    \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser carregado.   \n","        `encoding` - Codificação dos caracteres do arquivo.\n","    \"\"\"\n","\n","    # Abre o arquivo\n","    arquivo = open(nomeArquivo, \"r\", encoding= encoding)\n","    \n","    sentencas = []\n","    for linha in arquivo:        \n","        linha = linha.splitlines()\n","        linha = \" \".join(linha)\n","        linha = remove_tags(linha)\n","        if linha != \"\":\n","          sentencas.append(linha.strip())\n","    \n","    # Fecha o arquivo\n","    arquivo.close()\n","\n","    return sentencas "],"metadata":{"id":"EC9Xppq-_R0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def salvar(nomeArquivo,texto):                       \n","    \"\"\"\n","      Salva um texto em arquivo.\n","     \n","      Parâmetros:\n","        `nome_arquivo` - Nome do arquivo a ser salvo.\n","        `texto` - Texto a ser salvo.     \n","    \"\"\"\n","\n","    arquivo = open(nomeArquivo, \"w\")\n","    arquivo.write(str(texto))\n","    arquivo.close()"],"metadata":{"id":"fkVk5LQT_G3f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"603LYIYKBmq5"},"source":["Função auxiliar para formatar o tempo como `hh: mm: ss`"]},{"cell_type":"code","metadata":{"id":"Guy6B4whsZFR"},"source":["# Import das bibliotecas.\n","import time\n","import datetime\n","\n","def formataTempo(tempo):\n","    \"\"\"\n","      Pega a tempo em segundos e retorna uma string hh:mm:ss\n","    \"\"\"\n","    # Arredonda para o segundo mais próximo.\n","    tempoArredondado = int(round((tempo)))\n","    \n","    # Formata como hh:mm:ss\n","    return str(datetime.timedelta(seconds=tempoArredondado))    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zVKAapz7RCxk"},"source":["Classe(ModelArguments) de definição dos parâmetros do modelo"]},{"cell_type":"code","metadata":{"id":"zgmN6RqDRDZS"},"source":["# Import das bibliotecas.\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","from typing import List\n","\n","@dataclass\n","class ModeloArgumentosMedida:\n","    max_seq_len: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"max seq len\"},\n","    )    \n","    pretrained_model_name_or_path: str = field(\n","        default=\"neuralmind/bert-base-portuguese-cased\",\n","        metadata={\"help\": \"nome do modelo pré-treinado do BERT.\"},\n","    )\n","    modelo_spacy: str = field(\n","        default=\"pt_core_news_lg\",\n","        metadata={\"help\": \"nome do modelo do spaCy.\"},\n","    )\n","    versao_modelo_spacy: str = field(\n","        default=\"-3.2.0\",\n","        metadata={\"help\": \"versão do nome do modelo no spaCy.\"},\n","    )\n","    sentenciar_documento: bool = field(\n","        default=True,\n","        metadata={\"help\": \"Dividir o documento em sentenças(frases).\"},\n","    )\n","    janela: int = field(\n","        default=\"0\",\n","        metadata={\"help\": \"Quantidade de sentenças que formam a janela de texto a ser submetido ao BERT.\"},\n","    )\n","    do_lower_case: bool = field(\n","        default=False,\n","        metadata={\"help\": \"define se o texto do modelo deve ser todo em minúsculo.\"},\n","    )    \n","    output_attentions: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita se o modelo retorna os pesos de atenção.\"},\n","    )\n","    output_hidden_states: bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita gerar as camadas ocultas do modelo.\"},\n","    )   \n","    usar_mcl_ajustado : bool = field(\n","        default=False,\n","        metadata={\"help\": \"habilita o carragamento de mcl ajustado.\"},\n","    )\n","    documentos_perturbados: int = field(\n","        default=\"1\",\n","        metadata={\"help\": \"Quantidade de documentos a serem perturbados a partir do original.\"},\n","    )\n","    top_k_predicao: int = field(\n","        default=\"100\",\n","        metadata={\"help\": \"Quantidade de palavras a serem recuperadas mais próximas da máscara.\"},\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HIN413rj50EI"},"source":["Biblioteca de limpeza de tela\n"]},{"cell_type":"code","metadata":{"id":"bxV4-3Yg50EI"},"source":["# Import das bibliotecas.\n","from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iAPVtRXQqDim"},"source":["## 1.3 Tratamento de logs"]},{"cell_type":"code","metadata":{"id":"DcopxbGZqDip"},"source":["# Import das bibliotecas.\n","import logging # Biblioteca de logging\n","\n","# Formatando a mensagem de logging\n","logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GjYtXcMnSAe"},"source":["## 1.4 Identificando o ambiente Colab"]},{"cell_type":"code","metadata":{"id":"YMiH0E3OnRa1"},"source":["# Import das bibliotecas.\n","import sys # Biblioteca para acessar módulos do sistema\n","\n","# Se estiver executando no Google Colaboratory\n","# Retorna true ou false se estiver no Google Colaboratory\n","IN_COLAB = \"google.colab\" in sys.modules"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yuHoA4Dx6K1M"},"source":["## 1.5 Colaboratory"]},{"cell_type":"markdown","metadata":{"id":"0zhAltEP6K1M"},"source":["Usando Colab GPU para Treinamento\n"]},{"cell_type":"markdown","metadata":{"id":"IxAlgXv66K1M"},"source":["Uma GPU pode ser adicionada acessando o menu e selecionando:\n","\n","`Edit -> Notebook Settings -> Hardware accelerator -> (GPU)`\n","\n","Em seguida, execute a célula a seguir para confirmar que a GPU foi detectada."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828257640,"user_tz":180,"elapsed":3702,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"1cdfcd90-54c1-446d-c033-4235d8ba591c","id":"Cmva6ltA6K1M"},"source":["# Import das bibliotecas.\n","import tensorflow as tf\n","\n","# Recupera o nome do dispositido da GPU.\n","device_name = tf.test.gpu_device_name()\n","\n","# O nome do dispositivo deve ser parecido com o seguinte:\n","if device_name == \"/device:GPU:0\":\n","    logging.info(\"Encontrei GPU em: {}\".format(device_name))    \n","else:\n","    logging.info(\"Dispositivo GPU não encontrado\")\n","    #raise SystemError(\"Dispositivo GPU não encontrado\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:17:36,563 : INFO : NumExpr defaulting to 2 threads.\n","2022-03-09 12:17:37,304 : INFO : Dispositivo GPU não encontrado\n"]}]},{"cell_type":"markdown","metadata":{"id":"XrC2SG3x6K1M"},"source":["Nome da GPU\n","\n","Para que a torch use a GPU, precisamos identificar e especificar a GPU como o dispositivo. Posteriormente, em nosso ciclo de treinamento, carregaremos dados no dispositivo.\n","\n","Vale a pena observar qual GPU você recebeu. A GPU Tesla P100 é muito mais rápido que as outras GPUs, abaixo uma lista ordenada:\n","- 1o Tesla P100\n","- 2o Tesla T4\n","- 3o Tesla P4 (Não tem memória para execução 4 x 8, somente 2 x 4)\n","- 4o Tesla K80 (Não tem memória para execução 4 x 8, somente 2 x 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOnQUkWZ6K1N"},"outputs":[],"source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def getDeviceGPU():\n","    \"\"\"\n","    Retorna um dispositivo de GPU se disponível ou CPU.\n","    \n","    Retorno:\n","    `device` - Um device de GPU ou CPU.       \n","    \"\"\"\n","        \n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():\n","        \n","        # Diz ao PyTorch para usar GPU.    \n","        device = torch.device(\"cuda\")\n","        \n","        logging.info(\"Existem {} GPU(s) disponíveis.\".format(torch.cuda.device_count()))\n","        logging.info(\"Iremos usar a GPU: {}.\".format(torch.cuda.get_device_name(0)))\n","\n","    # Se não.\n","    else:        \n","        logging.info(\"Sem GPU disponível, usando CPU.\")\n","        device = torch.device(\"cpu\")\n","        \n","    return device"]},{"cell_type":"code","source":["device = getDeviceGPU()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828265480,"user_tz":180,"elapsed":64,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"7144389f-adf8-412a-b582-5ba684c277f7","id":"WcMhNxsE6K1N"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:17:44,877 : INFO : Sem GPU disponível, usando CPU.\n"]}]},{"cell_type":"markdown","source":["Conecta o modelo ao device"],"metadata":{"id":"kkdlEouHftcJ"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import torch # Biblioteca para manipular os tensores\n","\n","def conectaGPU(model, device):\n","    \"\"\"\n","      Conecta um modelo BERT a GPU.\n","\n","      Parâmetros:\n","        `model` - Um modelo BERT carregado.       \n","        `device` - Um device de GPU.     \n","    \n","      Retorno:\n","        `model` - Um objeto model BERT conectado a GPU.     \n","    \"\"\"\n","    # Associa a GPU ao modelo.\n","    model.to(device)\n","\n","    # Se existe GPU disponível.\n","    if torch.cuda.is_available():    \n","        # Diga ao pytorch para rodar este modelo na GPU.\n","        logging.info(\"Pytorch rodando o modelo na GPU.\")\n","        model.cuda()\n","        \n","    else:\n","        logging.info(\"Pytorch rodando sem GPU.\")\n","\n","    return model"],"metadata":{"id":"a-znVDGyfsVx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRdtvR_J6K1N"},"source":["Memória\n","\n","Memória disponível no ambiente"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828265483,"user_tz":180,"elapsed":26,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"95ed3dee-85af-409d-d494-8c90767eb968","id":"hSmGz55H6K1N"},"source":["# Importando as bibliotecas.\n","from psutil import virtual_memory\n","\n","ram_gb = virtual_memory().total / 1e9\n","logging.info(\"Seu ambiente de execução tem {: .1f} gigabytes de RAM disponível\\n\".format(ram_gb))\n","\n","if ram_gb < 20:\n","  logging.info(\"Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \\\"Alterar tipo de tempo de execução\\\"\")\n","  logging.info(\"e selecione High-RAM. Então, execute novamente está célula\")\n","else:\n","  logging.info(\"Você está usando um ambiente de execução de memória RAM alta!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:17:44,977 : INFO : Seu ambiente de execução tem  13.6 gigabytes de RAM disponível\n","\n","2022-03-09 12:17:44,989 : INFO : Para habilitar um tempo de execução de RAM alta, selecione menu o ambiente de execução> \"Alterar tipo de tempo de execução\"\n","2022-03-09 12:17:44,994 : INFO : e selecione High-RAM. Então, execute novamente está célula\n"]}]},{"cell_type":"markdown","metadata":{"id":"wijMXooQQLcQ"},"source":["## 1.6 Monta uma pasta no google drive para carregar os arquivos de dados."]},{"cell_type":"code","metadata":{"id":"ysnDDapMQK8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828319939,"user_tz":180,"elapsed":54469,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"15ec2fc0-4e1a-4d19-9a3d-1d0bab4a847b"},"source":["# import necessário\n","from google.colab import drive\n","\n","# Monta o drive na pasta especificada\n","drive.mount(\"/content/drive\")     "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"u66iRrtwMrqy"},"source":["## 1.7 Instalação do wandb"]},{"cell_type":"markdown","metadata":{"id":"dQd3BrhvMzZs"},"source":["Instalação"]},{"cell_type":"code","metadata":{"id":"ejzpgGrFM0-j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828330858,"user_tz":180,"elapsed":10928,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"2ee7947f-7dbb-40fd-be4d-2b52365fd135"},"source":["!pip install --upgrade wandb"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.11-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 4.2 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.7-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 44.5 MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 47.6 MB/s \n","\u001b[?25hCollecting setproctitle\n","  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=7828b15a407a6c6be7cf9de1b27dc2045b06675b73dab01a8f08113848405d65\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, yaspin, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.7 setproctitle-1.2.2 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.11 yaspin-2.1.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"J0LeiOTx0Dlk"},"source":["## 1.8 Instalação do spaCy\n","\n","https://spacy.io/\n","\n","Modelos do spaCy para português:\n","https://spacy.io/models/pt"]},{"cell_type":"code","metadata":{"id":"EaMM4WdxgvQ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828346645,"user_tz":180,"elapsed":15803,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"d7eec9e5-39ee-4dfa-91f5-938218389519"},"source":["# Instala o spacy\n","!pip install -U pip setuptools wheel"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-60.9.3-py3-none-any.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 45.0 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed pip-22.0.4 setuptools-60.9.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"w4p3Rz2qDq94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828372008,"user_tz":180,"elapsed":25367,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"6ea69f06-39fe-46d2-a0bb-ef00871c7549"},"source":["# Instala uma versão específica\n","!pip install -U spacy==3.2.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (21.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.0.6)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.21.5)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.10.0.2)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (3.0.6)\n","Collecting typer<0.5.0,>=0.3.0\n","  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (60.9.3)\n","Collecting pathy>=0.3.5\n","  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.8\n","  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n","Collecting spacy-loggers<2.0.0,>=1.0.0\n","  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.23.0)\n","Collecting srsly<3.0.0,>=2.4.1\n","  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.0/452.0 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n","  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n","Collecting langcodes<4.0.0,>=3.2.0\n","  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (0.9.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (1.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (4.63.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.0) (2.11.3)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.2/628.2 KB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.0) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.0) (3.0.7)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.0) (2.0.1)\n","Installing collected packages: typer, spacy-loggers, spacy-legacy, pydantic, langcodes, catalogue, srsly, pathy, thinc, spacy\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.0 spacy-legacy-3.0.9 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"Pqa-7WXBAw8q"},"source":["## 1.9 Instalação do BERT"]},{"cell_type":"markdown","metadata":{"id":"eCdqJCtQN52l"},"source":["Instala a interface pytorch para o BERT by Hugging Face. \n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"]},{"cell_type":"code","metadata":{"id":"1RfUN_KolV-f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828384786,"user_tz":180,"elapsed":12791,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"ed127d0b-94f1-49e3-dab9-dd6089548de5"},"source":["!pip install -U transformers==4.5.1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.5.1\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.63.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1) (4.11.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.1) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1) (1.1.0)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.5.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"8bGda5JgMtQe"},"source":["# 2 Parametrização"]},{"cell_type":"markdown","source":["## Gerais"],"metadata":{"id":"ifrYNTwGwKal"}},{"cell_type":"code","source":["# Definição dos parâmetros a serem avaliados\n","#Quantidade de documentos a serem perturbados a partir do original.\n","DOCUMENTOS_PERTURBADOS = 1 # Somente 1 para o Cohebert Manual\n","\n","#Quantidade de palavras a serem recuperadas mais próximas da máscara.\n","TOP_K_PREDICAO = 1 # Somente 1 para o Cohebert Manual"],"metadata":{"id":"5uiH9pNpwI6g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Específicos"],"metadata":{"id":"mhByVujAwNAU"}},{"cell_type":"code","metadata":{"id":"oJ15-ylRRRdD"},"source":["# Definição dos parâmetros do Modelo.\n","model_args = ModeloArgumentosMedida(     \n","    max_seq_len = 512, \n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-large-portuguese-cased/bert-large-portuguese-cased_pytorch_checkpoint.zip\",\n","    #pretrained_model_name_or_path = \"https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\",\n","    pretrained_model_name_or_path = \"neuralmind/bert-large-portuguese-cased\",\n","    #pretrained_model_name_or_path = \"neuralmind/bert-base-portuguese-cased\",    \n","    #pretrained_model_name_or_path = \"bert-base-multilingual-cased\",\n","    #pretrained_model_name_or_path = \"bert-base-multilingual-uncased\",\n","    modelo_spacy = \"pt_core_news_lg\",\n","    #modelo_spacy = \"pt_core_news_md\",\n","    #modelo_spacy = \"pt_core_news_sm\",\n","    versao_modelo_spacy = \"3.2.0\",\n","    sentenciar_documento = True,\n","    janela = 2,\n","    do_lower_case = False,   # default True  \n","    output_attentions = False,    # default False\n","    output_hidden_states = True, # default False, se True retorna todas as camadas do modelo para as operações de soma e concatenação\n","    usar_mcl_ajustado = False, # Especifica se deve ser carregado um MCL ajustado ou pré-treinado. Necessário especificar o tipo do modelo em pretrained_model_name_or_path.     \n","    documentos_perturbados = DOCUMENTOS_PERTURBADOS, # Quantidade de documentos a serem perturbados a partir do original.\n","    top_k_predicao = TOP_K_PREDICAO, # Conjunto de valores: 1, 10, 100, 500 e 1000. Quantidade de palavras a serem recuperadas mais próximas da máscara.\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Nome do diretório dos arquivos de dados"],"metadata":{"id":"WlF4PKP6Iopi"}},{"cell_type":"code","source":["# Diretório do cohebert\n","DIRETORIO_COHEBERT = \"COHEBERT_MANUAL\""],"metadata":{"id":"55PNP2s6Iopi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUxlx7Sx4yxj"},"source":["## Define o caminho para os arquivos de dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gQpxAO74yxj"},"outputs":[],"source":["# Diretório local para os arquivos pré-processados\n","DIRETORIO_LOCAL = \"/content/\" + DIRETORIO_COHEBERT + \"/\"\n","\n","# Diretório no google drive com os arquivos pré-processados\n","DIRETORIO_DRIVE = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/\""]},{"cell_type":"markdown","metadata":{"id":"L7G3-MOsQ1N_"},"source":["# 3 spaCy"]},{"cell_type":"markdown","metadata":{"id":"35GwcgkOlWi3"},"source":["## 3.1 Download arquivo modelo\n","\n","https://spacy.io/models/pt"]},{"cell_type":"markdown","source":["### Função download modelo spaCy"],"metadata":{"id":"PWd_9X0nOYnF"}},{"cell_type":"code","source":["def downloadSpacy(model_args):\n","    \"\"\"\n","      Realiza o download do arquivo do modelo para o diretório corrente.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","        \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Nome arquivo compactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    # Url do arquivo\n","    URL_ARQUIVO_MODELO_COMPACTADO = \"https://github.com/explosion/spacy-models/releases/download/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO\n","\n","    # Realiza o download do arquivo do modelo\n","    logging.info(\"Download do arquivo do modelo do spaCy.\")\n","    downloadArquivo(URL_ARQUIVO_MODELO_COMPACTADO, DIRETORIO_COHEBERT + \"/\" + NOME_ARQUIVO_MODELO_COMPACTADO)"],"metadata":{"id":"DjWGu-9D5URZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uu_LkF7Nfm8_"},"source":["## 3.2 Descompacta o arquivo do modelo"]},{"cell_type":"markdown","source":["### Função descompacta modelo spaCy"],"metadata":{"id":"XAc1tSwvOc4d"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import tarfile # Biblioteca de descompactação\n","\n","def descompactaSpacy(model_args):\n","    \"\"\"\n","      Descompacta o arquivo do modelo.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    \n","    # Nome do arquivo a ser descompactado\n","    NOME_ARQUIVO_MODELO_COMPACTADO = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \".tar.gz\"\n","    \n","    logging.info(\"Descompactando o arquivo do modelo do spaCy.\")\n","    arquivoTar = tarfile.open(NOME_ARQUIVO_MODELO_COMPACTADO, \"r:gz\")    \n","    arquivoTar.extractall(DIRETORIO_COHEBERT)    \n","    arquivoTar.close()\n","    \n","    # Apaga o arquivo compactado\n","    if os.path.isfile(NOME_ARQUIVO_MODELO_COMPACTADO):        \n","        os.remove(NOME_ARQUIVO_MODELO_COMPACTADO)"],"metadata":{"id":"Dq9PnXO77bPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STHT2c89qvwK"},"source":["## 3.3 Carrega o modelo"]},{"cell_type":"markdown","source":["### Função carrega modelo spaCy"],"metadata":{"id":"3iFBoyWMOgKz"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import spacy # Biblioteca do spaCy\n","\n","def carregaSpacy(model_args):\n","    \"\"\"\n","    Realiza o carregamento do Spacy.\n","    \n","    Parâmetros:\n","      `model_args` - Objeto com os argumentos do modelo.           \n","    \"\"\"\n","    \n","    # Verifica se existe o diretório base\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","                  \n","    # Nome arquivo spacy\n","    ARQUIVO_MODELO_SPACY = model_args.modelo_spacy\n","    # Versão spaCy\n","    VERSAO_SPACY = \"-\" + model_args.versao_modelo_spacy\n","    # Caminho raoz do modelo do spaCy\n","    DIRETORIO_MODELO_SPACY =  DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY\n","\n","    # Verifica se o diretório existe\n","    if os.path.exists(DIRETORIO_MODELO_SPACY) == False:\n","        # Realiza o download do arquivo modelo do spaCy\n","        downloadSpacy(model_args)\n","        # Descompacta o spaCy\n","        descompactaSpacy(model_args)\n","\n","    # Diretório completo do spaCy\n","    DIRETORIO_MODELO_SPACY = DIRETORIO_COHEBERT + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + \"/\" + ARQUIVO_MODELO_SPACY + VERSAO_SPACY + \"/\"\n","\n","    # Carrega o spaCy. Necessário somente \"tagger\" para encontrar os substantivos\n","    nlp = spacy.load(DIRETORIO_MODELO_SPACY)\n","    logging.info(\"spaCy carregado.\")\n","\n","    # Retorna o spacy carregado\n","    return nlp "],"metadata":{"id":"ePOccj0s8WMg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Carrega o modelo spaCy\n"],"metadata":{"id":"cAk5hHx7OnHn"}},{"cell_type":"code","metadata":{"id":"nbELnrpgA4T1","colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["4039fe4566054bb79de440bb1bc00b3d","c43765dc21c84e7e9ebea0099460b2ed","d099f97dfaf54cd8bf693dfdc882d728","db92cc2a006f4a5ab7fbcedcbad2454d","ff752d3ac84d40b18de90fbb73c4f4e0","3e77a838139849f18bcfdd785d3a6f67","caee92a77bf5484c84c93e229ed08046","4dd929f0af5e4dc4b4700d8fa13e9288","9ada8986b0704ea5b47f564f2212f7c6","6ab282f630244f7cbceba9aa5e7539ea","b9b17ad94aeb49fdb279fc190e48d981"]},"executionInfo":{"status":"ok","timestamp":1646828451642,"user_tz":180,"elapsed":64945,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"1a6cf7f9-0c89-441a-e111-201917e07f59"},"source":["# Carrega o modelo spaCy\n","nlp = carregaSpacy(model_args)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:19:46,399 : INFO : Diretório Cohebert criado: COHEBERT_MANUAL\n","2022-03-09 12:19:46,404 : INFO : Download do arquivo do modelo do spaCy.\n","2022-03-09 12:19:47,332 : INFO : Download do arquivo: COHEBERT_MANUAL/pt_core_news_lg-3.2.0.tar.gz.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4039fe4566054bb79de440bb1bc00b3d","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/577M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2022-03-09 12:20:36,227 : INFO : Descompactando o arquivo do modelo do spaCy.\n","2022-03-09 12:20:51,061 : INFO : spaCy carregado.\n"]}]},{"cell_type":"markdown","metadata":{"id":"fzk8VOp7oy8n"},"source":["## 3.4 Funções auxiliares spaCy"]},{"cell_type":"markdown","source":["### getStopwords\n","\n","Recupera as stopwords do spaCy"],"metadata":{"id":"AEzytjZi5Iw2"}},{"cell_type":"code","metadata":{"id":"zKg-_XyWoy8o"},"source":["def getStopwords(nlp):\n","    \"\"\"\n","      Recupera as stop words do nlp(Spacy).\n","    \n","      Parâmetros:\n","        `nlp` - Um modelo spaCy carregado.           \n","    \"\"\"\n","    \n","    spacy_stopwords = nlp.Defaults.stop_words\n","\n","    return spacy_stopwords "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZdNFrC3oy8p"},"source":["Lista dos stopwords"]},{"cell_type":"code","metadata":{"id":"s1o8jevtoy8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828451644,"user_tz":180,"elapsed":24,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"8a198bae-047b-47d3-ce95-e3dd66dcbecb"},"source":["logging.info(\"Quantidade de stopwords: {}.\".format(len(getStopwords(nlp))))\n","\n","print(getStopwords(nlp))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:20:51,089 : INFO : Quantidade de stopwords: 416.\n"]},{"output_type":"stream","name":"stdout","text":["{'assim', 'foi', 'sempre', 'embora', 'do', 'povo', 'aquela', 'pelo', 'com', 'pôde', 'dos', 'favor', 'estiveste', 'podia', 'tão', 'minha', 'mil', 'mês', 'tiveste', 'fora', 'nesta', 'põe', 'naquele', 'pela', 'pelos', 'num', 'local', 'corrente', 'nessa', 'estou', 'fazes', 'possivelmente', 'esteve', 'já', 'vezes', 'de', 'são', 'bastante', 'conhecido', 'dois', 'dá', 'perto', 'dezoito', 'vocês', 'des', 'porém', 'cuja', 'ambos', 'nove', 'dão', 'quatro', 'muito', 'nosso', 'as', 'vinte', 'esses', 'depois', 'cá', 'para', 'obrigada', 'meu', 'essa', 'demais', 'veja', 'sei', 'quem', 'catorze', 'vos', 'fazem', 'eles', 'ver', 'estás', 'menos', 'tua', 'numa', 'além', 'sétima', 'tarde', 'vossa', 'qual', 'nunca', 'coisa', 'ou', 'nós', 'enquanto', 'sobre', 'daquele', 'sem', 'sexta', 'quando', 'está', 'breve', 'comprida', 'fará', 'menor', 'dez', 'segundo', 'lá', 'da', 'faço', 'deste', 'todo', 'boa', 'ontem', 'e', 'sistema', 'maior', 'das', 'meses', 'sexto', 'treze', 'tive', 'desde', 'fazia', 'neste', 'lugar', 'muitos', 'posso', 'se', 'estas', 'ir', 'estão', 'fim', 'três', 'era', 'falta', 'disso', 'quarta', 'quero', 'tentar', 'umas', 'dezassete', 'és', 'fostes', 'ponto', 'tente', 'foram', 'à', 'duas', 'próxima', 'próximo', 'antes', 'tanta', 'cedo', 'te', 'sétimo', 'entre', 'ao', 'põem', 'diz', 'sob', 'na', 'dizem', 'fazer', 'maiorias', 'logo', 'desta', 'estivestes', 'pode', 'cada', 'área', 'novo', 'exemplo', 'algumas', 'meio', 'nas', 'aquilo', 'aqueles', 'podem', 'ser', 'tivemos', 'uma', 'também', 'devem', 'estiveram', 'todos', 'estive', 'forma', 'suas', 'números', 'portanto', 'ali', 'custa', 'algo', 'faz', 'o', 'direita', 'nível', 'quer', 'saber', 'contudo', 'nossos', 'outros', 'tem', 'por', 'primeira', 'lhe', 'alguns', 'vais', 'teus', 'sete', 'apoio', 'me', 'porquanto', 'tentaram', 'nada', 'apenas', 'pois', 'dentro', 'às', 'daquela', 'terceira', 'fazemos', 'novas', 'último', 'outras', 'sua', 'ligado', 'fui', 'dessa', 'qualquer', 'os', 'vinda', 'novos', 'obrigado', 'puderam', 'aquelas', 'naquela', 'for', 'quieto', 'foste', 'aí', 'mesmo', 'segunda', 'têm', 'valor', 'ainda', 'aquele', 'teve', 'bem', 'onde', 'partir', 'poder', 'só', 'diante', 'debaixo', 'nos', 'tendes', 'aos', 'nenhuma', 'cujo', 'sim', 'terceiro', 'vai', 'tempo', 'através', 'tivestes', 'pegar', 'oitavo', 'seus', 'aqui', 'estivemos', 'momento', 'usa', 'longe', 'sou', 'quê', 'certamente', 'tipo', 'atrás', 'pouco', 'doze', 'querem', 'quinta', 'deve', 'cinco', 'estado', 'até', 'dezanove', 'um', 'todas', 'bom', 'fez', 'estava', 'meus', 'posição', 'tanto', 'desse', 'grupo', 'toda', 'tentei', 'vossas', 'nossas', 'esta', 'após', 'dizer', 'oito', 'iniciar', 'nova', 'outra', 'somente', 'grandes', 'somos', 'estes', 'eu', 'uns', 'mais', 'irá', 'não', 'no', 'grande', 'teu', 'tal', 'conhecida', 'agora', 'mas', 'vem', 'tuas', 'ela', 'vários', 'contra', 'apontar', 'nuns', 'possível', 'nossa', 'zero', 'fomos', 'próprio', 'ter', 'parte', 'temos', 'usar', 'tiveram', 'primeiro', 'seis', 'estar', 'vêm', 'isso', 'lado', 'deverá', 'eventual', 'como', 'pontos', 'nem', 'vez', 'talvez', 'sois', 'comprido', 'adeus', 'maioria', 'vão', 'máximo', 'tens', 'tu', 'quais', 'tenho', 'seria', 'este', 'seu', 'ele', 'a', 'quinto', 'esse', 'certeza', 'pelas', 'parece', 'estará', 'pouca', 'final', 'porquê', 'número', 'vós', 'inicio', 'poderá', 'baixo', 'quanto', 'minhas', 'fazeis', 'ademais', 'porque', 'relação', 'quieta', 'é', 'vossos', 'você', 'vindo', 'tais', 'acerca', 'oitava', 'questão', 'cento', 'ora', 'tudo', 'inclusive', 'ambas', 'vosso', 'onze', 'quarto', 'sabe', 'cima', 'isto', 'caminho', 'quinze', 'apoia', 'conselho', 'dar', 'então', 'nesse', 'geral', 'dezasseis', 'essas', 'em', 'que', 'elas', 'vens', 'mal'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"onM1ZApom-_W"},"source":["### getVerbos\n","Localiza os verbos da sentença"]},{"cell_type":"code","metadata":{"id":"6hdqVdfxm-_W"},"source":["# Import das bibliotecas.\n","import spacy   \n","from spacy.util import filter_spans\n","from spacy.matcher import Matcher\n","\n","# (verbo normal como auxilar ou auxilar) + vários verbos auxiliares +verbo principal ou verbo auxiliar\n","gramaticav1 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                                  \n","                {\"POS\": \"VERB\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"ROOT\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo normal como auxiliar\n","                {\"POS\": \"AUX\", \"OP\": \"*\", \"DEP\": {\"IN\": [\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar   \n","                {\"POS\": \"VERB\", \"OP\": \"+\"}, #verbo principal\n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\",\"aux\",\"xcomp\",\"aux:pass\"]}},  #verbo auxiliar\n","               ] \n","\n","# verbo auxiliar + verbo normal como auxiliar + conjunção com preposição + verbo\n","gramaticav2 =  [               \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"aux\",\"aux:pass\"]}},  #verbo auxiliar                   \n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}},  #verbo principal       \n","                {\"POS\": \"SCONJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"mark\"]}}, #conjunção com preposição\n","                {\"POS\": \"VERB\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"xcomp\"]}}, #verbo normal como complementar\n","               ] \n","\n","#Somente verbos auxiliares\n","gramaticav3 =  [\n","                {\"POS\": \"AUX\", \"OP\": \"?\"},  #Verbos auxiliar \n","                {\"POS\": \"AUX\", \"OP\": \"?\", \"DEP\": {\"IN\": [\"cop\"]}},  #Verbos auxiliar de ligação (AUX+(cop))\n","                {\"POS\": \"ADJ\", \"OP\": \"+\", \"DEP\": {\"IN\": [\"ROOT\"]}}, \n","                {\"POS\": \"AUX\", \"OP\": \"?\"}  #Verbos auxiliar \n","               ] \n","\n","matcherv = Matcher(nlp.vocab)\n","         \n","matcherv.add(\"frase verbal\", [gramaticav1])\n","matcherv.add(\"frase verbal\", [gramaticav2])\n","matcherv.add(\"frase verbal\", [gramaticav3])\n","\n","#Retorna a Frase Verbal\n","def getVerbos(periodo):    \n","  #Processa o período\n","  doc1 = nlp(periodo.text)\n","  \n","  # Chama o mather para encontrar o padrão\n","  matches = matcherv(doc1)\n","\n","  padrao = [doc1[start:end] for _, start, end in matches]\n","\n","  #elimina as repetições e sobreposições\n","  #return filter_spans(padrao)\n","  lista1 = filter_spans(padrao)\n","\n","  # Converte os itens em string\n","  lista2 = []\n","  for x in lista1:\n","      lista2.append(str(x))\n","  \n","  return lista2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ZVwbmn3Nx2t"},"source":["### getDicPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j3VF4NOSPbq"},"outputs":[],"source":["def getDicPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades\n","  novodic = dict()\n","  \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uPDYU4KBC5q"},"outputs":[],"source":["def getDicTodasPOSQtde(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Retorna inteiros que mapeiam para classes gramaticais\n","  conta_dicionarios = doc.count_by(spacy.attrs.IDS[\"POS\"])\n","\n","  # Dicionário com as tags e quantidades    \n","  novodic = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\":0, \"X\": 0}\n","    \n","  for pos, qtde in conta_dicionarios.items():\n","    classe_gramatical = doc.vocab[pos].text\n","    novodic[classe_gramatical] = qtde\n","\n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"Jxe-mh-l6sJY"},"source":["### getDicTodasPOSQtde\n","\n","Conta as POS Tagging de uma sentença"]},{"cell_type":"code","metadata":{"id":"j9SA61kD6sJY"},"source":["def getDicTodasPOSQtde(lista):\n","\n","  # Dicionário com as tags e quantidades\n","  conjunto = {\"PRON\":0, \"VERB\":0, \"PUNCT\":0, \"DET\":0, \"NOUN\":0, \"AUX\":0, \"CCONJ\":0, \"ADP\":0, \"PROPN\":0, \"ADJ\":0, \"ADV\":0, \"NUM\":0, \"SCONJ\":0, \"SYM\":0, \"SPACE\":0, \"INTJ\": 0}\n","\n","  for x in lista:\n","    valor = conjunto.get(x)\n","    if valor != None:\n","      conjunto[x] = valor + 1\n","    else:\n","      conjunto[x] = 1\n","\n","  return conjunto"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m4KV_jI-Nx2w"},"source":["### getSomaDic\n","\n","Soma os valores de dicionários com as mesmas chaves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGduPM6HNx2w"},"outputs":[],"source":["from collections import Counter\n","from functools import reduce\n","\n","def atualizaValor(a,b):\n","    a.update(b)\n","    return a\n","\n","def getSomaDic(lista):\n","    \n","  # Soma os dicionários da lista\n","  novodic = reduce(atualizaValor, (Counter(dict(x)) for x in lista))\n"," \n","  return novodic"]},{"cell_type":"markdown","metadata":{"id":"bGaf7bkpAEiX"},"source":["### getTokensSentenca\n","\n","Retorna a lista de tokens da sentenca."]},{"cell_type":"code","metadata":{"id":"gWxyAo54AOHU"},"source":["def getTokensSentenca(sentenca):\n","\n","    # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.text)\n","\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZB6bR42PA28c"},"source":["### getPOSTokensSentenca\n","\n","Retorna a lista das POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awaqjNIZA3Fk"},"outputs":[],"source":["def getPOSTokensSentenca(sentenca):\n","\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença adicionando os tokens\n","  for token in doc:    \n","    lista.append(token.pos_)\n","\n","  return lista"]},{"cell_type":"markdown","metadata":{"id":"B4Soqt3fp3Lu"},"source":["### getListaTokensPOSSentenca\n","\n","Retorna duas listas uma com os tokens e a outra com a POS-Tagging dos tokens da sentenca."]},{"cell_type":"code","metadata":{"id":"Gvd99wd_pwmt"},"source":["def getListaTokensPOSSentenca(sentenca):\n","  # Verifica se o sentenca não foi processado pelo spaCy  \n","  if type(sentenca) is not spacy.tokens.doc.Doc:\n","      # Realiza o parsing no spacy\n","      doc = nlp(sentenca)\n","  else:\n","      doc = sentenca\n","\n","  # Lista dos tokens\n","  listatokens = []\n","  listapos = []\n","\n","  # Percorre a sentença adicionando os tokens e as POS\n","  for token in doc:    \n","    listatokens.append(token.text)\n","    listapos.append(token.pos_)\n","    \n","  return listatokens, listapos"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ENvsIER06sJX"},"source":["### Tadução das tags"]},{"cell_type":"markdown","metadata":{"id":"kwSb3ECU6sJY"},"source":["Tags de palavras universal\n","\n","https://universaldependencies.org/u/pos/\n","\n","Detalhes das tags em português:\n","http://www.dbd.puc-rio.br/pergamum/tesesabertas/1412298_2016_completo.pdf"]},{"cell_type":"code","metadata":{"id":"NpCUpOs06sJY"},"source":["#dicionário que contêm pos tag universal e suas explicações\n","palavrauniversal_dict = {\n","  \"X\"    : \"Outro\",\n","  \"VERB\" : \"Verbo \",\n","  \"SYM\"  : \"Símbolo\",\n","  \"CONJ\" : \"Conjunção\",\n","  \"SCONJ\": \"Conjunção subordinativa\",\n","  \"PUNCT\": \"Pontuação\",\n","  \"PROPN\": \"Nome próprio\",\n","  \"PRON\" : \"Pronome substativo\",\n","  \"PART\" : \"Partícula, morfemas livres\",\n","  \"NUM\"  : \"Numeral\",\n","  \"NOUN\" : \"Substantivo\",\n","  \"INTJ\" : \"Interjeição\",\n","  \"DET\"  : \"Determinante, Artigo e pronomes adjetivos\",\n","  \"CCONJ\": \"Conjunção coordenativa\",\n","  \"AUX\"  : \"Verbo auxiliar\",\n","  \"ADV\"  : \"Advérbio\",\n","  \"ADP\"  : \"Preposição\",\n","  \"ADJ\"  : \"Adjetivo\"\n","}\n","  \n","#Explica a POS\n","def traduzPOSPalavraUniversal(palavra):\n","  if palavra in palavrauniversal_dict.keys():\n","      traduzido = palavrauniversal_dict[palavra]\n","  else:\n","      traduzido = \"NA\" \n","  return traduzido"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b01WgMSSKY_u"},"source":["### getSentencaSemStopWord\n","\n","Retorna uma lista dos tokens sem as stopwords."]},{"cell_type":"code","metadata":{"id":"rMb0uDWzKZXP"},"source":["def getSentencaSemStopWord(sentenca, stopwords):\n","\n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre os tokens da sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é uma stopword\n","    if token.lower() not in stopwords:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TouR4GjNJZD6"},"source":["### getSentencaSalientePOS\n","\n","Retorna uma lista das palavras do tipo especificado."]},{"cell_type":"code","metadata":{"id":"zxTCYFzcJZD6"},"source":["def getSentencaSalientePOS(sentenca, pos, tipoSaliente=\"NOUN\"):\n","  \n","  # Lista dos tokens\n","  lista = []\n","\n","  # Percorre a sentença\n","  for i, token in enumerate(sentenca):\n","\n","    # Verifica se o token é do tipo especeficado\n","    if pos[i] == tipoSaliente:\n","      lista.append(token)\n","\n","  # Retorna o documento\n","  return lista"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xaeX0oTVQ5t"},"source":["###removeStopWords\n","\n","Remove as stopwords de um documento ou senteça."]},{"cell_type":"code","metadata":{"id":"NIaQ9bzBVQ5t"},"source":["def removeStopWord(documento, stopwords):\n","  \n","  # Remoção das stopwords do documento\n","  documentoSemStopwords = [palavra for palavra in documento.split() if palavra.lower() not in stopwords]\n","\n","  # Concatena o documento sem os stopwords\n","  documentoLimpo = \" \".join(documentoSemStopwords)\n","\n","  # Retorna o documento\n","  return documentoLimpo"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7NAe8ogCf1y"},"source":["### retornaRelevante\n","\n","Retorna somente os palavras do documento ou sentença do tipo especificado."]},{"cell_type":"code","metadata":{"id":"UNNfykypChn-"},"source":["def retornaRelevante(documento, classeRelevante=\"NOUN\"):\n","\n","  # Corrigir!\n","  # Utilizar o documento já tokenizado pelo spacy!!!!\n","  # Existe uma lista com o documento e a sentença tokenizada pelo spacy\n","  \n","  # Realiza o parsing no spacy\n","  doc = nlp(documento)\n","\n","  # Retorna a lista das palavras relevantes\n","  documentoComSubstantivos = []\n","  for token in doc:\n","    #print(\"token:\", token.pos_)\n","    if token.pos_ == classeRelevante:\n","      documentoComSubstantivos.append(token.text)\n","\n","  # Concatena o documento com os substantivos\n","  documentoConcatenado = \" \".join(documentoComSubstantivos)\n","\n","  # Retorna o documento\n","  return documentoConcatenado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IBY7q_uH8JSE"},"source":["# 4 BERT"]},{"cell_type":"markdown","source":["## 4.1 Modelo Pré-treinado BERT"],"metadata":{"id":"MBGTMy8Ic7GK"}},{"cell_type":"markdown","source":["### Funções Auxiliares"],"metadata":{"id":"uiuxdXe9t1BX"}},{"cell_type":"code","source":["def getNomeModeloBERT(model_args):\n","    '''    \n","    Recupera uma string com uma descrição do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `MODELO_BERT` - Nome do modelo BERT.\n","    '''\n","\n","    # Verifica o nome do modelo(default SEM_MODELO_BERT)\n","    MODELO_BERT = \"SEM_MODELO_BERT\"\n","    \n","    if 'neuralmind' in model_args.pretrained_model_name_or_path:\n","        MODELO_BERT = \"_BERTimbau\"\n","        \n","    else:\n","        if 'multilingual' in model_args.pretrained_model_name_or_path:\n","            MODELO_BERT = \"_BERTmultilingual\"\n","            \n","    return MODELO_BERT"],"metadata":{"id":"9Huw0x5kt1Le"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getTamanhoBERT(model_args):\n","    '''    \n","    Recupera uma string com o tamanho(dimensão) do modelo BERT para nomes de arquivos e diretórios.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.       \n","    \n","    Retorno:\n","    `TAMANHO_BERT` - Nome do tamanho do modelo BERT.\n","    '''\n","    \n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = \"_large\"\n","    \n","    if 'base' in model_args.pretrained_model_name_or_path:\n","        TAMANHO_BERT = \"_base\"\n","        \n","    return TAMANHO_BERT  "],"metadata":{"id":"jYJB4ik7t5xe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Função download Modelo Pre-treinado BERT"],"metadata":{"id":"rHt4e5pAcEMd"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import zipfile # Biblioteca para descompactar\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def downloadModeloPretreinado(model_args):\n","    \"\"\"\n","      Realiza o download do modelo BERT(MODELO) e retorna o diretório onde o modelo BERT(MODELO) foi descompactado.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","    \n","    # Nome diretório base modelo BERT\n","    NOME_DIRETORIO_BASE_MODELO = \"modeloBERT\"\n","    \n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","    \n","    # Recupera o nome ou caminho do modelo\n","    MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in MODELO:\n","        URL_MODELO = MODELO\n","\n","    # Se a variável foi setada.\n","    if URL_MODELO:\n","\n","        # Diretório do modelo.\n","        DIRETORIO_MODELO = DIRETORIO_COHEBERT + \"/\" + NOME_DIRETORIO_BASE_MODELO\n","        \n","        # Recupera o nome do arquivo do modelo da url.\n","        NOME_ARQUIVO = URL_MODELO.split(\"/\")[-1]\n","\n","        # Nome do arquivo do vocabulário.\n","        ARQUIVO_VOCAB = \"vocab.txt\"\n","        \n","        # Caminho do arquivo na url.\n","        CAMINHO_ARQUIVO = URL_MODELO[0:len(URL_MODELO)-len(NOME_ARQUIVO)]\n","\n","        # Verifica se o diretório de descompactação existe no diretório corrente\n","        if os.path.exists(DIRETORIO_MODELO):\n","            logging.info(\"Apagando diretório existente do modelo!\")\n","            # Apaga o diretório e os arquivos existentes                     \n","            shutil.rmtree(DIRETORIO_MODELO)\n","        \n","        # Realiza o download do arquivo do modelo        \n","        downloadArquivo(URL_MODELO, NOME_ARQUIVO)\n","\n","        # Descompacta o arquivo no diretório de descompactação.                \n","        arquivoZip = zipfile.ZipFile(NOME_ARQUIVO, \"r\")\n","        arquivoZip.extractall(DIRETORIO_MODELO)\n","\n","        # Baixa o arquivo do vocabulário.\n","        # O vocabulário não está no arquivo compactado acima, mesma url mas arquivo diferente.\n","        URL_MODELO_VOCAB = CAMINHO_ARQUIVO + ARQUIVO_VOCAB\n","        # Coloca o arquivo do vocabulário no diretório do modelo.        \n","        downloadArquivo(URL_MODELO_VOCAB, DIRETORIO_MODELO + \"/\" + ARQUIVO_VOCAB)\n","        \n","        # Apaga o arquivo compactado\n","        os.remove(NOME_ARQUIVO)\n","\n","        logging.info(\"Diretório {} do modelo BERT pronta!\".format(DIRETORIO_MODELO))\n","\n","    else:\n","        DIRETORIO_MODELO = MODELO\n","        logging.info(\"Variável URL_MODELO não setada!\")\n","\n","    return DIRETORIO_MODELO"],"metadata":{"id":"peDUrV2ccEXA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Copia o modelo do BERT ajustado"],"metadata":{"id":"V74WUpHqcfoI"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import shutil # iblioteca de manipulação arquivos de alto nível\n","\n","def copiaModeloAjustado(model_args):\n","    \"\"\" \n","      Copia o modelo ajustado BERT do GoogleDrive para o projeto.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.\n","    \n","      Retorno:\n","        `DIRETORIO_LOCAL_MODELO_AJUSTADO` - Diretório de download ajustado do modelo.\n","    \"\"\"\n","\n","    # Verifica o nome do modelo BERT a ser utilizado\n","    MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","    # Verifica o tamanho do modelo(default large)\n","    TAMANHO_BERT = getTamanhoBERT(model_args)\n","\n","    # Verifica se existe o diretório base do cohebert e retorna o nome do diretório\n","    DIRETORIO_COHEBERT = verificaDiretorioCoheBERT()\n","\n","    # Diretório local de salvamento do modelo.\n","    DIRETORIO_LOCAL_MODELO_AJUSTADO = DIRETORIO_COHEBERT + \"/modelo_ajustado/\"\n","\n","    # Diretório remoto de salvamento do modelo no google drive.\n","    DIRETORIO_REMOTO_MODELO_AJUSTADO = \"/content/drive/MyDrive/Colab Notebooks/Data/\" + DIRETORIO_COHEBERT + \"/validacao_classificacao_palavra/holdout/modelo/\" + MODELO_BERT + TAMANHO_BERT\n","\n","    # Copia o arquivo do modelo para o diretório no Google Drive.\n","    shutil.copytree(DIRETORIO_REMOTO_MODELO_AJUSTADO, DIRETORIO_LOCAL_MODELO_AJUSTADO) \n","   \n","    logging.info(\"Modelo BERT ajustado copiado!\")\n","\n","    return DIRETORIO_LOCAL_MODELO_AJUSTADO"],"metadata":{"id":"iQMpf9yycf8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Verifica de onde utilizar o modelo do BERT"],"metadata":{"id":"eaneOhAKcO-3"}},{"cell_type":"code","source":["def verificaModelo(model_args):\n","    \"\"\" \n","    Verifica de onde utilizar o modelo.\n","    \n","    Parâmetros:\n","    `model_args` - Objeto com os argumentos do modelo.\n","    \n","    Retorno:\n","    `DIRETORIO_MODELO` - Diretório de download do modelo.\n","    \"\"\" \n","\n","    DIRETORIO_MODELO = None\n","    \n","    if model_args.usar_mcl_ajustado == True:        \n","        # Diretório do modelo\n","        DIRETORIO_MODELO = copiaModeloAjustado()\n","        \n","        logging.info(\"Usando modelo BERT ajustado.\")\n","        \n","    else:\n","        DIRETORIO_MODELO = downloadModeloPretreinado(model_args)\n","        logging.info(\"Usando modelo BERT pré-treinado.\")        \n","        \n","    return DIRETORIO_MODELO"],"metadata":{"id":"TTy1TXz3cPKS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Tokenizador BERT"],"metadata":{"id":"6tKcaIfReqdy"}},{"cell_type":"markdown","source":["### Função carrega Tokenizador BERT\n","\n","O tokenizador utiliza WordPiece, veja em [artigo original](https://arxiv.org/pdf/1609.08144.pdf)."],"metadata":{"id":"e8n7Z5s-QZF8"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","from transformers import BertTokenizer # Importando as bibliotecas do tokenizador BERT.\n","\n","def carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o tokenizador do DIRETORIO_MODELO.\n","      O tokenizador utiliza WordPiece.\n","      Carregando o tokenizador do diretório \"./modelo/\" do diretório padrão se variável `DIRETORIO_MODELO` setada.\n","      Caso contrário carrega da comunidade\n","      Por default(`do_lower_case=True`) todas as letras são colocadas para minúsculas. Para ignorar a conversão para minúsculo use o parâmetro `do_lower_case=False`. Esta opção também considera as letras acentuadas(ãçéí...), que são necessárias a língua portuguesa.\n","      O parâmetro `do_lower_case` interfere na quantidade tokens a ser gerado a partir de um texto. Quando igual a `False` reduz a quantidade de tokens gerados.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.       \n","    \n","      Retorno:\n","        `tokenizer` - Tokenizador BERT.\n","    \"\"\"\n","\n","    tokenizer = None\n","    \n","    # Se a variável DIRETORIO_MODELO foi setada.\n","    if DIRETORIO_MODELO:\n","        # Carregando o Tokenizador.\n","        logging.info(\"Carregando o tokenizador BERT do diretório {}.\".format(DIRETORIO_MODELO))\n","\n","        tokenizer = BertTokenizer.from_pretrained(DIRETORIO_MODELO, do_lower_case=model_args.do_lower_case)\n","\n","    else:\n","        # Carregando o Tokenizador da comunidade.\n","        logging.info(\"Carregando o tokenizador BERT da comunidade.\")\n","\n","        tokenizer = BertTokenizer.from_pretrained(model_args.pretrained_model_name_or_path, do_lower_case=model_args.do_lower_case)\n","\n","    return tokenizer"],"metadata":{"id":"mzAuptkwQZR3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Carrega o modelo e tokenizador BERT\n","\n","Lista de modelos da comunidade:\n","* https://huggingface.co/models\n","\n","Português(https://github.com/neuralmind-ai/portuguese-bert):  \n","* **\"neuralmind/bert-base-portuguese-cased\"**\n","* **\"neuralmind/bert-large-portuguese-cased\"**"],"metadata":{"id":"GYRV9KfHQE6v"}},{"cell_type":"markdown","source":["### Função carrega modelo BERT medida"],"metadata":{"id":"-pZZrUKRhR3e"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","from transformers import BertModel # Importando as bibliotecas do Modelo BERT.\n","\n","def carregaModeloMedida(DIRETORIO_MODELO, model_args):\n","    \"\"\"\n","      Carrega o modelo e retorna o modelo.\n","    \n","      Parâmetros:\n","        `DIRETORIO_MODELO` - Diretório a ser utilizado pelo modelo BERT.           \n","        `model_args` - Objeto com os argumentos do modelo.   \n","    \n","      Retorno:\n","        `model` - Um objeto do modelo BERT carregado.\n","    \"\"\"\n","\n","    # Variável para setar o arquivo.\n","    URL_MODELO = None\n","\n","    if \"http\" in model_args.pretrained_model_name_or_path:\n","        URL_MODELO = model_args.pretrained_model_name_or_path\n","\n","    # Se a variável URL_MODELO foi setada\n","    if URL_MODELO:        \n","        # Carregando o Modelo BERT\n","        logging.info(\"Carregando o modelo BERT do diretório {} para cálculo de medidas.\".format(DIRETORIO_MODELO))\n","\n","        model = BertModel.from_pretrained(DIRETORIO_MODELO,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","        \n","    else:\n","        # Carregando o Modelo BERT da comunidade\n","        logging.info(\"Carregando o modelo BERT da comunidade {} para cálculo de medidas.\".format(model_args.pretrained_model_name_or_path))\n","\n","        model = BertModel.from_pretrained(model_args.pretrained_model_name_or_path,\n","                                          output_attentions=model_args.output_attentions,\n","                                          output_hidden_states=model_args.output_hidden_states)\n","\n","    return model"],"metadata":{"id":"1JUEyjCChUQh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Função carrega o BERT"],"metadata":{"id":"-uFDhRTZe2Js"}},{"cell_type":"code","source":["def carregaBERT(model_args):\n","    \"\"\" \n","      Carrega o BERT para cálculo de medida ou classificação e retorna o modelo e o tokenizador.\n","      O tipo do model retornado pode ser BertModel ou BertForSequenceClassification, depende do tipo de model_args.\n","    \n","      Parâmetros:\n","        `model_args` - Objeto com os argumentos do modelo.       \n","          - Se model_args = ModeloArgumentosClassificacao deve ser carregado o BERT para classificação(BertForSequenceClassification).\n","          - Se model_args = ModeloArgumentosMedida deve ser carregado o BERT para cálculo de medida(BertModel).\n","\n","      Retorno:    \n","        `model` - Um objeto do modelo BERT carregado.       \n","        `tokenizer` - Um objeto tokenizador BERT carregado.       \n","    \"\"\"\n","            \n","    # Verifica a origem do modelo\n","    DIRETORIO_MODELO = verificaModelo(model_args)\n","    \n","    # Variável para conter o modelo\n","    model = None\n","    \n","    # Carrega o modelo para cálculo da medida\n","    model = carregaModeloMedida(DIRETORIO_MODELO, model_args)\n","                \n","    # Carrega o tokenizador. \n","    # O tokenizador é o mesmo para o classificador e medidor.\n","    tokenizer = carregaTokenizadorModeloPretreinado(DIRETORIO_MODELO, model_args)\n","    \n","    return model, tokenizer"],"metadata":{"id":"QVtAUbUBe2iS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Carrega o BERT"],"metadata":{"id":"x5NTxBRKfAcT"}},{"cell_type":"code","source":["# Carrega o modelo e tokenizador do BERT\n","model, tokenizer = carregaBERT(model_args)"],"metadata":{"id":"ZYMLJJYSQHY3","colab":{"base_uri":"https://localhost:8080/","height":205,"referenced_widgets":["30bbb442dd12432598ea3291a57849af","fdf7d69e13d04141a958fd67f4a412b9","078af941f7454cb480181364c5e8e824","6f45afe417df4e2cb1fc0ad9d44ebb89","4cc5be02ecd64b16b06ad34cbf5019b5","4c1055c2660a43ed9f81228547d1325b","07a347a3dd9041c4912470b47fd03822","59c0b4628c944a74a1a82682eec94022","d888666150ce497894afeafde24523cc","51a5281c94504939a964a618089a54c0","2d901edced3f4ea09475e6e9910ea5ec","a4423d840de548899b9dfeb6196e64ae","8a58b95cf9b04fcbadb863e87b4641d9","221bfd6dc918419d995780d5d546399b","bd394692954044f394b328910c7a65a2","75586a3711374bd48aa63283a94b8127","8daef25e62474a02a660feab87cacd00","a4336a06ff334cb186956f876a693a5e","33e3992279ab45c8a710b9892ed68678","7550c307349c4885b2b796f347f5230f","47c330de6a9047eebf966d6e211f9b27","7b877e2f9cf5494bbb7a762499bb98b3"]},"executionInfo":{"status":"ok","timestamp":1646828566686,"user_tz":180,"elapsed":114421,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"cea1c34f-8bb0-4f50-a6e7-2bd73b15235d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:20:52,617 : INFO : Download do arquivo: bert-large-portuguese-cased_pytorch_checkpoint.zip.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30bbb442dd12432598ea3291a57849af","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/1.24G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:37,634 : INFO : Download do arquivo: COHEBERT_MANUAL/modeloBERT/vocab.txt.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4423d840de548899b9dfeb6196e64ae","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/210k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:38,377 : INFO : Diretório COHEBERT_MANUAL/modeloBERT do modelo BERT pronta!\n","2022-03-09 12:22:38,555 : INFO : Usando modelo BERT pré-treinado.\n","2022-03-09 12:22:38,557 : INFO : Carregando o modelo BERT do diretório COHEBERT_MANUAL/modeloBERT para cálculo de medidas.\n","2022-03-09 12:22:46,121 : INFO : Carregando o tokenizador BERT do diretório COHEBERT_MANUAL/modeloBERT.\n"]}]},{"cell_type":"markdown","metadata":{"id":"d7KprWqyZBQZ"},"source":["### Recupera detalhes do BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6sPjTQnuQV2"},"outputs":[],"source":["# Verifica o nome do modelo BERT a ser utilizado\n","MODELO_BERT = getNomeModeloBERT(model_args)\n","\n","# Verifica o tamanho do modelo(default large)\n","TAMANHO_BERT = getTamanhoBERT(model_args)"]},{"cell_type":"markdown","metadata":{"id":"khTFfBVbnsx9"},"source":["## 4.4 Funções auxiliares do BERT"]},{"cell_type":"markdown","source":["### getJanelasLista"],"metadata":{"id":"70eyg_DVy_ql"}},{"cell_type":"code","source":["def getJanelaSentenca(lista, janela, passo, indice_passo):\n","  \"\"\" \n","     Cria janelas de itens de uma lista\n","         \n","     Parâmetros:\n","       `lista` - Um dataframe com os documentos.\n","       `janela` - Tamanho da janela a ser montada.\n","       `passo` - Passo ser deslocado na  janela.\n","       `indice_passo` - Índice do passo que se deseja da janela.\n","\n","     Retorno:    \n","       `lista_janela` - Lista com os documentos em janelas.\n","       `string_janela` - String com os documentos em janelas.\n","  \"\"\"\n","  # Percorre a lista  \n","  # Dentro do intervalo dos passos\n","  #if indice_sentenca >= 0 and indice_sentenca < len(lista):\n","  if indice_passo >= 0 and indice_passo < len(lista):\n","      # Seleciona o passo que se deseja a janela de \n","      #i = indice_passo\n","      #print(\"\\nPasso :\", i)\n","      \n","      # Guarda os itens da janela\n","      lista_janela = []   \n","      \n","      # Inicio da lista sem janelas completas antes do passo\n","      if indice_passo < janela:  \n","\n","        #print(\"Inicio da lista\") \n","        # Sentenças anteriores\n","        #Evita estourar o início da lista\n","        inicio = 0\n","        fim = indice_passo\n","        for j in range(inicio, fim):                  \n","          documento_original = lista.iloc[j]\n","          documento = documento_original['documento']\n","          lista_janela.append(documento)\n","\n","        # Sentença central\n","        documento_original = lista.iloc[indice_passo]\n","        documento = documento_original['documento']\n","        lista_janela.append(documento)\n","        \n","        # Sentenças posteriores\n","        inicio = indice_passo + 1\n","        fim = indice_passo + janela + 1\n","        for j in range(inicio,fim):        \n","          documento_original = lista.iloc[j]\n","          documento = documento_original['documento']\n","          lista_janela.append(documento)\n","                    \n","      else:\n","        # Meio da lista com janelas completas antes e depois\n","        if indice_passo < len(lista)-janela:          \n","          #print(\" Meio da lista\")\n","\n","          # Sentenças anteriores\n","          inicio = indice_passo - janela         \n","          fim = indice_passo\n","          for j in range(inicio, fim):          \n","            documento_original = lista.iloc[j]\n","            documento = documento_original['documento']\n","            lista_janela.append(documento)\n","                        \n","          # Sentença central\n","          documento_original = lista.iloc[indice_passo]\n","          documento = documento_original['documento']\n","          lista_janela.append(documento)\n","\n","          # Sentenças posteriores\n","          inicio = indice_passo + 1\n","          fim = indice_passo + 1 + janela\n","          for j in range(inicio,fim):      \n","            documento_original = lista.iloc[j]\n","            documento = documento_original['documento']\n","            lista_janela.append(documento)            \n","\n","        else:\n","          # Fim da lista sem janelas completas depois\n","          if indice_passo >= len(lista)-janela:            \n","            #print(\"Fim da lista\")    \n","            \n","            # Sentenças anteriores\n","            inicio = i - janela\n","            fim = i\n","            for j in range(inicio, fim):\n","              documento_original = lista.iloc[j]\n","              documento = documento_original['documento']\n","              lista_janela.append(documento)\n","                  \n","            # Sentença central\n","            docucmento_original = lista.iloc[indice_passo]\n","            documento = documento_original['documento']\n","            lista_janela.append(documento)\n","                        \n","            # Sentenças posteriores\n","            inicio = indice_passo + 1\n","            fim = indice_passo + 1 + janela \n","            # Evita o extrapolar o limite da lista de sentenças\n","            if fim > len(lista):\n","              fim = len(lista)\n","            for j in range(inicio,fim):\n","              documento_original = lista.iloc[j]\n","              documento = documento_original['documento']\n","              lista_janela.append(documento)\n","                    \n","  else:\n","    logging.info(\"Índice fora do intervalo da lista de passos.\")\n","\n","  return lista_janela, \" \".join(lista_janela)"],"metadata":{"id":"WGG5NWw3y_9m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### concatenaListas"],"metadata":{"id":"lCJzsw8T0I-5"}},{"cell_type":"code","source":["def concatenaListas(lista, pos=1):\n","  listaConcat = []\n","\n","  for x in lista:\n","      listaConcat = listaConcat + x[pos]\n","  \n","  return listaConcat"],"metadata":{"id":"IpmDZ1mI0JHR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s42mgtmSZ8MR"},"source":["### getEmbeddingsCamadas\n","\n","Funções que recuperam os embeddings das camadas:\n","- Primeira camada;\n","- Penúltima camada;\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"sgo3EBTRZ9-3"},"source":["def getEmbeddingPrimeiraCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","      \n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  resultado = output[2][0]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  \n","  return resultado\n","\n","def getEmbeddingPenultimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","      \n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  resultado = output[2][-2]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  \n","  return resultado\n","\n","def getEmbeddingUltimaCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","     \n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  resultado = output[2][-1]\n","  # Saída: (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  \n","  return resultado    \n","\n","def getEmbeddingSoma4UltimasCamadas(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","      \n","  # Retorna todas a primeira(-1) camada\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  embeddingCamadas = output[2][-4:]\n","  # Saída: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","\n","  # Usa o método `stack` para criar uma nova dimensão no tensor \n","  # com a concateção dos tensores dos embeddings.        \n","  #Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  resultadoStack = torch.stack(embeddingCamadas, dim=0)\n","  # Saída: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  \n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <4> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultadoStack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  \n","  return resultado\n","\n","def getEmbeddingConcat4UltimasCamadas(output):  \n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","      \n","  # Cria uma lista com os tensores a serem concatenados\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)  \n","  # Lista com os tensores a serem concatenados  \n","  listaConcat = []\n","\n","  # Percorre os 4 últimos\n","  for i in [-1,-2,-3,-4]:\n","      # Concatena da lista\n","      listaConcat.append(output[2][i])\n","\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)    \n","  # Realiza a concatenação dos embeddings de todos as camadas\n","  # Saída: Entrada: List das camadas(4) (<1(lote)> x <qtde_tokens> x <768 ou 1024>)  \n","  resultado = torch.cat(listaConcat, dim=-1)\n","  \n","  # Saída: Entrada: (<1(lote)> x <qtde_tokens> x <3072 ou 4096>)    \n","  return resultado   \n","\n","def getEmbeddingSomaTodasAsCamada(output):\n","  # outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","  # hidden_states é uma lista python, e cada elemento um tensor pytorch no formado <lote> x <qtde_tokens> x <768 ou 1024>.\n","   \n","  # Retorna todas as camadas descontando a primeira(0)\n","  # Entrada: List das camadas(13 ou 25) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  embeddingCamadas = output[2][1:]\n","  # Saída: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  \n","  # Usa o método `stack` para criar uma nova dimensão no tensor \n","  # com a concateção dos tensores dos embeddings.        \n","  #Entrada: List das camadas(12 ou 24) (<1(lote)> x <qtde_tokens> <768 ou 1024>)  \n","  resultadoStack = torch.stack(embeddingCamadas, dim=0)\n","  # Saída: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","    \n","  # Realiza a soma dos embeddings de todos os tokens para as camadas\n","  # Entrada: <12 ou 24> x <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","  resultado = torch.sum(resultadoStack, dim=0)\n","  # Saida: <1(lote)> x <qtde_tokens> x <768 ou 1024>\n","    \n","  return resultado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q7nx_eZ8hSlr"},"source":["### getEmbeddingsVisual\n","\n","Função para gerar as coordenadas de plotagem a partir das sentenças de embeddings.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"pLdbOT8-g43V"},"source":["def getEmbeddingsVisualUltimaCamada(documento, modelo, tokenizer):\n","    \n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","    \n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","    \n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding    \n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAf9lJJ2hZbt"},"source":["def getEmbeddingsVisualSoma4UltimasCamadas(documento, modelo, tokenizer):\n","    \n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","    \n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","    \n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding    \n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XpwSN1ghpnz"},"source":["def getEmbeddingsVisualConcat4UltimasCamadas(documento, modelo, tokenizer):\n","    \n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","    \n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","    \n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding        \n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3KU1EFrnSPK"},"source":["def getEmbeddingsVisualSomaTodasAsCamadas(documento, modelo, tokenizer):\n","    \n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","    \n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","    \n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding    \n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    # Recupera os embeddings dos tokens como um vetor\n","    embeddings = token_embeddings.numpy()\n","\n","    # Converte para um array\n","    W = np.array(embeddings)\n","    # Transforma em um array\n","    B = np.array([embeddings[0], embeddings[-1]])\n","    # Invertee B.T\n","    Bi = np.linalg.pinv(B.T)\n","\n","    #Projeta a palavra no espaço\n","    Wp = np.matmul(Bi,W.T)\n","\n","    return Wp, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y8MjE0utzlZT"},"source":["### getEmbeddings\n","\n","Função para gerar os embeddings de sentenças.\n","\n","Existe uma função para os tipos de camadas utilizadas:\n","- Ùltima camada;\n","- Soma das 4 últimas camadas;\n","- Concatenação das 4 últimas camadas;\n","- Soma de todas as camadas."]},{"cell_type":"code","metadata":{"id":"2QcqOuwS067Q"},"source":["def getEmbeddingsUltimaCamada(documento, modelo, tokenizer):\n","    \n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","    \n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","    \n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding    \n","    camada = getEmbeddingUltimaCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n"," \n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BK1wDGBl067Y"},"source":["def getEmbeddingsSoma4UltimasCamadas(documento, modelo, tokenizer):\n","    \n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","    \n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","    \n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding    \n","    camada = getEmbeddingSoma4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","   \n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hym19Hxr067Y"},"source":["def getEmbeddingsConcat4UltimasCamadas(documento, modelo, tokenizer):\n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","    \n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","    \n","    # Camada embedding    \n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getEmbeddingsConcat4UltimasCamadasJanela(documento, janela_documento, modelo, tokenizer):\n","    # Adiciona os tokens especiais\n","    janela_documento_marcado = \"[CLS] \" + janela_documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    janela_documento_tokenizado = tokenizer.tokenize(janela_documento_marcado)\n","    \n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(janela_documento_tokenizado)\n","\n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(janela_documento_tokenizado)\n","    \n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","\n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","    \n","    # Camada embedding    \n","    camada = getEmbeddingConcat4UltimasCamadas(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","    #print(\"token_embeddings=\", token_embeddings.shape)\n","    \n","    # Divide a sentença em tokens para procurar na janela\n","    documento_tokenizado = tokenizer.tokenize(documento)\n","\n","    # Procura o local de início e fim do documento na janela\n","    inicio, fim = encontrarIndiceSubLista(janela_documento_tokenizado, documento_tokenizado)\n","    #print(\"Inicio:\",inicio,\" Fim:\",fim) \n"," \n","    # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n","    token_embeddings_retorno = token_embeddings[inicio:fim+1]\n","    #print(\"token_embeddings_retorno=\", token_embeddings_retorno.shape)\n","\n","    return token_embeddings_retorno, documento_tokenizado"],"metadata":{"id":"H6FI8SrCz8-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-PLZiUR067Z"},"source":["def getEmbeddingsSomaTodasAsCamadas(documento, modelo, tokenizer):\n","    \n","    # Adiciona os tokens especiais\n","    documento_marcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Divide a sentença em tokens\n","    documento_tokenizado = tokenizer.tokenize(documento_marcado)\n","\n","    # Mapeia as strings dos tokens em seus índices do vocabuário    \n","    tokens_indexados = tokenizer.convert_tokens_to_ids(documento_tokenizado)\n","    \n","    # Marca cada um dos tokens como pertencentes à sentença \"1\".\n","    mascara_atencao = [1] * len(documento_tokenizado)\n","\n","    # Converte a entrada em tensores\n","    tokens_tensores = torch.as_tensor([tokens_indexados])\n","    mascara_atencao_tensores = torch.as_tensor([mascara_atencao])\n","    \n","    # Prediz os atributos dos estados ocultos para cada camada\n","    with torch.no_grad():        \n","        # Retorno de model quando ´output_hidden_states=True´ é setado:  \n","        #outputs[0] = last_hidden_state, outputs[1] = pooler_output, outputs[2] = hidden_states\n","        outputs = modelo(tokens_tensores, mascara_atencao_tensores)\n","\n","    # Camada embedding    \n","    camada = getEmbeddingSomaTodasAsCamada(outputs)\n","\n","    # Remove a dimensão 1, o lote \"batches\".\n","    token_embeddings = torch.squeeze(camada, dim=0)\n","\n","    return token_embeddings, documento_tokenizado"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFd1rse11DpZ"},"source":["### getDocumentoTokenizado \n","\n","Retorna o documento tokenizado"]},{"cell_type":"code","metadata":{"id":"gvWIBFTLJ7z9"},"source":["def getDocumentoTokenizado(documento, tokenizer):\n","    \"\"\"\n","      Retorna o documento tokenizado pelo BERT.\n","    \n","      Parâmetros:\n","      `documento` - Documento a ser tokenizado.\n","      `tokenizer` - Tokenizador do BERT.\n","    \"\"\"    \n","\n","    # Adiciona os tokens especiais.\n","    documentoMarcado = \"[CLS] \" + documento + \" [SEP]\"\n","\n","    # Documento tokenizado\n","    documentoTokenizado = tokenizer.tokenize(documentoMarcado)\n","\n","    del tokenizer\n","\n","    return documentoTokenizado    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3wvgXwN81RCz"},"source":["### encontrarIndiceSubLista \n","\n","Retorna os índices de início e fim da sublista na lista"]},{"cell_type":"code","metadata":{"id":"abS44M4yvFxf"},"source":["# Localiza os índices de início e fim de uma sublista em uma lista\n","def encontrarIndiceSubLista(lista, sublista):\n","\n","    \"\"\"\n","      Localiza os índices de início e fim de uma sublista em uma lista.\n","    \n","      Parâmetros:\n","      `lista` - Uma lista.\n","      `sublista` - Uma sublista a ser localizada na lista.\n","    \"\"\"    \n","    # https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm\n","\n","    # Recupera o tamanho da lista \n","    h = len(lista)\n","    # Recupera o tamanho da sublista\n","    n = len(sublista)    \n","    skip = {sublista[i]: n - i - 1 for i in range(n - 1)}\n","    i = n - 1\n","    while i < h:\n","        for j in range(n):\n","            if lista[i - j] != sublista[-j - 1]:\n","                i += skip.get(lista[i], n)\n","                break\n","        else:\n","            indiceInicio = i - n + 1\n","            indiceFim = indiceInicio + len(sublista)-1\n","            return indiceInicio, indiceFim\n","    return -1, -1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGL37G6XFcwp"},"source":["### getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras\n","\n","A partir dos embeddings do documento, localiza o indíce de início e fim de uma sentença no documento e retorna os embeddings da sentença."]},{"cell_type":"code","metadata":{"id":"uI07Y_M8__HG"},"source":["def getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embeddingDocumento, \n","                                                           tokenBERTDocumento, \n","                                                           sentenca, \n","                                                           tokenizer):\n","\n","  # Tokeniza a sentença\n","  sentencaTokenizadaBert = getDocumentoTokenizado(sentenca, tokenizer)\n","  #print(sentencaTokenizadaBert)\n","\n","  # Remove os tokens de início e fim da sentença\n","  sentencaTokenizadaBert.remove(\"[CLS]\")\n","  sentencaTokenizadaBert.remove(\"[SEP]\")    \n","  #print(len(sentencaTokenizadaBert))\n","  \n","  # Localiza os índices dos tokens da sentença no documento\n","  inicio, fim = encontrarIndiceSubLista(tokenBERTDocumento, sentencaTokenizadaBert)\n","  #print(inicio,fim) \n"," \n","  # Recupera os embeddings dos tokens da sentença a partir dos embeddings do documento\n","  embeddingSentenca = embeddingDocumento[inicio:fim+1]\n","  #print(\"embeddingSentenca=\", embeddingSentenca.shape)\n","\n","  del tokenizer\n","  del tokenBERTDocumento\n","  del embeddingDocumento\n","  \n","  # Retorna o embedding da sentença no documento\n","  return embeddingSentenca, sentencaTokenizadaBert"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"THFhXGGmIO_r"},"source":["### getEmbeddingDocumentoComTodasPalavrasMean"]},{"cell_type":"code","metadata":{"id":"IhW_OiEsIPJI"},"source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoComTodasPalavrasMean(embeddingDocumento):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento excluindo os tokens \n","    especiais [CLS] do início e [SEP] do fim.\n","    Remove primeira dimensão devido ao cálculo da média.\n","    \n","    Parâmetros:\n","    `embeddingDocumento` - Embedding do documento.\n","  \"\"\"\n","\n","\n","  # Calcula a média dos embeddings para os tokens de embeddingDocumento, removendo a primeira dimensão.\n","  # Entrada: <qtde_tokens> x <768 ou 1024>  \n","  #print(\"embeddingDocumento1=\", embeddingDocumento.shape)\n","  mediaEmbeddingDocumento = torch.mean(embeddingDocumento[1:-1], dim=0)    \n","  # Saída: <768 ou 1024>\n","\n","  del embeddingDocumento\n","\n","  return mediaEmbeddingDocumento"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingDocumentoRelevanteMean"],"metadata":{"id":"1Ko_of60YuNd"}},{"cell_type":"code","source":["# Importa a biblioteca\n","import torch\n","\n","def getEmbeddingDocumentoRelevanteMean(id_documento, indexsentenca, embeddingDocumento, tokenBERTDocumento, documento, token_documento, pos_documento, filtro):\n","  \"\"\"\n","    Calcula a média dos embeddings do documento considerando tokens do tipo \n","    especificado no filtro\n","    Remove primeira dimensão devido ao cálculo da média.\n","    \n","    Parâmetros:    \n","    `embeddingDocumento` - Embeddings do documento gerados pelo BERT.\n","    `tokenBERTDocumento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","\n","  \"\"\"  \n","   \n","  # Recupera a lista de tokens do documento, a lista dos postagging e a lista dos seus embeddings com um mesmo tamanho\n","  listaTokens, listaPOS, listaEmbeddings = getTokensEmbeddingsPOSSentenca(id_documento, indexsentenca, embeddingDocumento, tokenBERTDocumento, documento, token_documento, pos_documento)\n","\n","  #print(\"len(tokenBERTDocumento):\", len(tokenBERTDocumento))\n","  #print(\"tokenBERTDocumento:\", tokenBERTDocumento)\n","  #print(\"len(pos_documento):\", len(pos_documento))\n","  #print(\"pos_documento:\", pos_documento)\n","  #print(\"filtro:\", filtro)\n","  #print()\n","\n","  # Lista com os tensores selecionados\n","  listaTokensSelecionados = []\n","  # Localizar os embeddings dos tokens da sentença tokenizada sem stop word no documento  \n","  for i, tokenDocumento in enumerate(listaTokens):     \n","      if (listaPOS[i] in filtro):          \n","          #print(\"Adicionando palavra do embedding:\", listaTokens[i])\n","          listaTokensSelecionados.append(listaEmbeddings[i])\n","\n","  if  len(listaTokensSelecionados) != 0:\n","      # Empila os embeddings da lista pela dimensão 0\n","      embeddingRelevante = torch.stack(listaTokensSelecionados, dim=0)\n","      #print(\"embeddingRelevante.shape:\",embeddingRelevante.shape)\n","\n","      # Calcula a média dos embeddings para os tokens de Si, removendo a primeira dimensão.\n","      # Entrada: <qtde_tokens> x <768 ou 1024>  \n","      mediaEmbeddingRelevante = torch.mean(embeddingRelevante, dim=0)    \n","      # Saída: <768 ou 1024>\n","      #print(\"mediaEmbeddingRelevante.shape:\", mediaEmbeddingRelevante.shape)\n","  else:\n","      mediaEmbeddingRelevante = None\n","\n","  del embeddingDocumento\n","  del tokenBERTDocumento\n","  del documento\n","  del tokenizer\n","  del token_documento\n","  del pos_documento\n","\n","  return mediaEmbeddingRelevante"],"metadata":{"id":"wDokSSODY0Sf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### getEmbeddingDocumentoMean\n","\n","Filtros:\n","- ALL - Sentença com todas as palavras\n","- NOUN - Sentença somente com substantivos\n","- VERB - Sentença somente com verbos\n","- VERB,NOUN - Sentença somente com verbos e substantivos"],"metadata":{"id":"L_vknrk7YSpF"}},{"cell_type":"code","source":["def getEmbeddingDocumentoMean(id_documento, \n","                              indexsentenca, \n","                              embeddingDocumento, \n","                              tokenBERTDocumento, \n","                              documento, \n","                              tokenizer,\n","                              token_documento, \n","                              pos_documento, \n","                              filtro=[\"ALL\"]):  \n","  \"\"\"\n","    Rediciona o cálculo da média dos embeddings de acordo com o filtro especificado.\n","    \n","    Parâmetros:    \n","    `embeddingDocumento` - Embeddings do documento gerados pelo BERT.\n","    `tokenBERTDocumento` - Lista com os tokens do documento gerados pelo tokenizador BERT.\n","    `documento` - Texto com o documento.\n","    `tokenizer` - Tokenizador do BERT.\n","    `token_documento` - Lista com os tokens do documento.\n","    `pos_documento` - Lista com as POS-Tagging do documento.\n","    `filtro` - Filtro dos embeddings.\n","  \"\"\"\n","\n","  if \"ALL\" in filtro:\n","    return getEmbeddingDocumentoComTodasPalavrasMean(embeddingDocumento)\n","  else:\n","    return getEmbeddingDocumentoRelevanteMean(id_documento, indexsentenca, embeddingDocumento, tokenBERTDocumento, documento, token_documento, pos_documento, filtro)\n","    "],"metadata":{"id":"Pd8B76YyYS02"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y7W-7V3QFbpR"},"source":["# 5 Comparar Palavras"]},{"cell_type":"markdown","metadata":{"id":"oQUy9Tat2EF_"},"source":["## 5.1 Carregamento dos arquivos de dados originais "]},{"cell_type":"markdown","metadata":{"id":"bD_tNbBGPrnE"},"source":["#### 5.1.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"bNgwJRC2uGJb"},"source":["# Nome do arquivo\n","NOMEARQUIVOORIGINAL = \"original.csv\"\n","NOMEARQUIVOORIGINALCOMPACTADO = \"original.zip\"\n","NOMEARQUIVOORIGINALPOS = \"originalpos.csv\"\n","NOMEARQUIVOORIGINALPOSCOMPACTADO = \"originalpos.zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5.1.2 Cria o diretório local para receber os dados"],"metadata":{"id":"CGF4D4B1JY9P"}},{"cell_type":"code","metadata":{"id":"gFYIHcIHE985","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828567423,"user_tz":180,"elapsed":38,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"3eaa2c7f-04a4-46db-9bba-d262ac7f36d8"},"source":["# Importando as bibliotecas.\n","import os\n","\n","# Cria o diretório para receber os arquivos Originais e Permutados\n","# Diretório a ser criado\n","dirbase = DIRETORIO_LOCAL[:-1]\n","\n","if not os.path.exists(dirbase):  \n","    # Cria o diretório\n","    os.makedirs(dirbase)    \n","    logging.info(\"Diretório criado: {}.\".format(dirbase))\n","else:    \n","    logging.info(\"Diretório já existe: {}.\".format(dirbase))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:46,795 : INFO : Diretório já existe: /content/COHEBERT_MANUAL.\n"]}]},{"cell_type":"markdown","metadata":{"id":"D8A9syejCsD2"},"source":["### 5.1.3 Copia os arquivos do Google Drive para o Colaboratory"]},{"cell_type":"code","metadata":{"id":"pviuxToMCxQw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828569627,"user_tz":180,"elapsed":2231,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"216b78dc-e228-4fe6-99da-df82d676bfda"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","\n","  !cp \"$DIRETORIO_DRIVE$NOMEARQUIVOORIGINALCOMPACTADO\" \"$DIRETORIO_LOCAL\"\n","  !cp \"$DIRETORIO_DRIVE$NOMEARQUIVOORIGINALPOSCOMPACTADO\" \"$DIRETORIO_LOCAL\"\n"," \n","  logging.info(\"Terminei a cópia.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:49,213 : INFO : Terminei a cópia.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rFCvZ6CUmt-9"},"source":["Descompacta os arquivos\n","\n","Usa o unzip para descompactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens \n","*   `-d` Diretório de destino\n"]},{"cell_type":"code","metadata":{"id":"dbHl3d88mouc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828570244,"user_tz":180,"elapsed":621,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"cd131765-7651-42fa-e51b-5fabf66edf5b"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOMEARQUIVOORIGINALCOMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","  !unzip -o -j -q \"$DIRETORIO_LOCAL$NOMEARQUIVOORIGINALPOSCOMPACTADO\" -d \"$DIRETORIO_LOCAL\"\n","\n","  logging.info(\"Terminei a descompactação.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:49,702 : INFO : Terminei a descompactação.\n"]}]},{"cell_type":"markdown","metadata":{"id":"qzhYJNWJm1z4"},"source":["### 5.1.4 Carregamento das lista com os dados dos arquivos originais"]},{"cell_type":"markdown","metadata":{"id":"Usr1uRzQeJSb"},"source":["#### Carrega o arquivo dos dados originais e POS"]},{"cell_type":"code","metadata":{"id":"QRHlixdHEDTb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828570245,"user_tz":180,"elapsed":36,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"dbab887b-c2a3-43e1-bb02-64c849c7534b"},"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","lista_documentos_originais = pd.read_csv(DIRETORIO_LOCAL + NOMEARQUIVOORIGINAL, sep=\";\", encoding=\"UTF-8\")\n","lista_documentos_originais_pos = pd.read_csv(DIRETORIO_LOCAL + NOMEARQUIVOORIGINALPOS, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"TERMINADO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:49,758 : INFO : TERMINADO ORIGINAIS: 40.\n","2022-03-09 12:22:49,761 : INFO : TERMINADO ORIGINAIS POS: 40.\n"]}]},{"cell_type":"code","metadata":{"id":"jJ5STBZPLlie","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828570245,"user_tz":180,"elapsed":25,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"e3610188-662a-4d85-8802-be6c4501f06d"},"source":["lista_documentos_originais.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-fae9493e-62f2-42ba-84b9-1c18228683f9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentencas</th>\n","      <th>documento</th>\n","      <th>classe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>['Como empilhar e desempilhar elementos em uma...</td>\n","      <td>Como empilhar e desempilhar elementos em uma e...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>['O que é uma fila e como enfileirar seu eleme...</td>\n","      <td>O que é uma fila e como enfileirar seu elemento?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>['O que é uma fila e como empilhar seu element...</td>\n","      <td>O que é uma fila e como empilhar seu elemento?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>['Como empilhar elementos em uma estrutura de ...</td>\n","      <td>Como empilhar elementos em uma estrutura de da...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>['O que é uma pilha e como empilhar seu elemen...</td>\n","      <td>O que é uma pilha e como empilhar seu elemento?</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fae9493e-62f2-42ba-84b9-1c18228683f9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fae9493e-62f2-42ba-84b9-1c18228683f9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fae9493e-62f2-42ba-84b9-1c18228683f9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    id                                          sentencas  \\\n","11  12  ['Como empilhar e desempilhar elementos em uma...   \n","18  19  ['O que é uma fila e como enfileirar seu eleme...   \n","17  18  ['O que é uma fila e como empilhar seu element...   \n","8    9  ['Como empilhar elementos em uma estrutura de ...   \n","16  17  ['O que é uma pilha e como empilhar seu elemen...   \n","\n","                                            documento  classe  \n","11  Como empilhar e desempilhar elementos em uma e...       0  \n","18   O que é uma fila e como enfileirar seu elemento?       1  \n","17     O que é uma fila e como empilhar seu elemento?       0  \n","8   Como empilhar elementos em uma estrutura de da...       1  \n","16    O que é uma pilha e como empilhar seu elemento?       1  "]},"metadata":{},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"IbaWPXE2jK26","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828570245,"user_tz":180,"elapsed":22,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"67063838-fb3c-4954-f3f1-ab4084dcdd8a"},"source":["lista_documentos_originais_pos.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-21a033c2-3f86-4e1b-8b7f-7c3e486bf118\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pos_documento</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>[[['Como', 'desempilhar', 'elementos', 'em', '...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>25</td>\n","      <td>[[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>[[['Como', 'empilhar', 'e', 'desempilhar', 'el...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>32</td>\n","      <td>[[['O', 'que', 'é', 'uma', 'pilha', 'e', 'como...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>[[['Como', 'empilhar', 'elementos', 'em', 'uma...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a033c2-3f86-4e1b-8b7f-7c3e486bf118')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-21a033c2-3f86-4e1b-8b7f-7c3e486bf118 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-21a033c2-3f86-4e1b-8b7f-7c3e486bf118');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    id                                      pos_documento\n","12  13  [[['Como', 'desempilhar', 'elementos', 'em', '...\n","24  25  [[['O', 'que', 'é', 'uma', 'fila', 'e', 'como'...\n","10  11  [[['Como', 'empilhar', 'e', 'desempilhar', 'el...\n","31  32  [[['O', 'que', 'é', 'uma', 'pilha', 'e', 'como...\n","9   10  [[['Como', 'empilhar', 'elementos', 'em', 'uma..."]},"metadata":{},"execution_count":80}]},{"cell_type":"markdown","source":["#### Corrigir os tipos de colunas dos dados originais e POS\n","\n","Em dados originais:\n","- coluna 1 - `sentenças` carregadas do arquivo vem como string e não como lista.\n","\n","Em dados originais pos:\n","- coluna 1 - `pos_documento` carregadas do arquivo vem como string e não como lista."],"metadata":{"id":"-hfUpvKqXoqe"}},{"cell_type":"code","source":["# Import das bibliotecas.\n","import ast # Biblioteca para conversão de string em lista\n","\n","# Verifica se o tipo da coluna não é list e converte\n","lista_documentos_originais[\"sentencas\"] = lista_documentos_originais[\"sentencas\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","lista_documentos_originais_pos[\"pos_documento\"] = lista_documentos_originais_pos[\"pos_documento\"].apply(lambda x: ast.literal_eval(x) if type(x)!=list else x)\n","\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS: {}.\".format(len(lista_documentos_originais)))\n","logging.info(\"TERMINADO CORREÇÃO ORIGINAIS POS: {}.\".format(len(lista_documentos_originais_pos)))"],"metadata":{"id":"lj9sJVavMccj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828570246,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"1effd86d-7eba-49de-93d3-712186c9a6b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:49,876 : INFO : TERMINADO CORREÇÃO ORIGINAIS: 40.\n","2022-03-09 12:22:49,878 : INFO : TERMINADO CORREÇÃO ORIGINAIS POS: 40.\n"]}]},{"cell_type":"markdown","metadata":{"id":"d1yGaGzzyEiy"},"source":["## 5.2 Gerando as comparações\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xKaqQPs8VQ5u"},"source":["### 5.2.1 Medidas de similaridade \n"]},{"cell_type":"markdown","metadata":{"id":"jt06PTN5idrg"},"source":["Similaridade do cosseno entre os embeddings.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n","\n","A função spatial.distance.cosine do módulo scipy calcula a distância em vez da similaridade do cosseno, mas para conseguir isso, podemos subtrair o valor da distância de 1.\n","\n","Intervalo de [-1,1] \n","\n","Vetores iguais a distância é igual 1.\n","\n","Vetores diferentes medida próxima de -1."]},{"cell_type":"code","metadata":{"id":"6vbXj-brOlMF"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cosine\n","\n","def similaridadeCosseno(embeddings1, embeddings2):\n","    \"\"\"\n","      Similaridade do cosseno dos embeddings dos textos.\n","      \n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","    \n","    similaridade = 1 - cosine(embeddings1, embeddings2)\n","    \n","    return similaridade"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fazAuLMUr_c0"},"source":["### 5.2.2 Medidas de distância "]},{"cell_type":"markdown","metadata":{"id":"_IcrjAbhwake"},"source":["Distância euclidiana entre os embeddings.\n","\n","Possui outros nomes como distância L2 ou norma L2.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"]},{"cell_type":"code","metadata":{"id":"mIrTId9jwakh"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import euclidean\n","\n","def distanciaEuclidiana(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância euclidiana entre os embeddings dos textos.\n","      Possui outros nomes como distância L2 ou norma L2.\n","      \n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","    \n","    distancia = euclidean(embeddings1, embeddings2)\n","    \n","    return distancia"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-uJlqYCSXdVk"},"source":["Distância Manhattan entre os embeddings.\n","\n","Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","\n","https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"]},{"cell_type":"code","metadata":{"id":"jFG5UT_SXdVn"},"source":["# Import das bibliotecas.\n","from scipy.spatial.distance import cityblock\n","\n","def distanciaManhattan(embeddings1, embeddings2):\n","    \"\"\"\n","      Distância Manhattan entre os embeddings dos textos \n","      Possui outros nomes como distância Cityblock, distância L1, norma L1 e métrica do táxi.\n","      \n","      Parâmetros:\n","      `embeddings1` - Um embedding a ser medido.\n","      `embeddings2` - Um embedding a ser medido.\n","    \"\"\"\n","    \n","    distancia = cityblock(embeddings1, embeddings2)\n","\n","    return distancia"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6A6-Xwg8GJw"},"source":["### 5.2.3 Retorna todas as medidas dos embeddings"]},{"cell_type":"code","metadata":{"id":"qHzQ98zg8GWJ"},"source":["def getMedidasEmbedding(embeddingWi, embeddingWj):\n","\n","  \"\"\"\n","    Retorna as medidas de similaridade do cosseno(cos), distância Euclidiana(euc) e \n","    distância de Manhattan(man) entre os embeddings.\n","        \n","    Parâmetros:\n","    `embeddingsWi` - Um embedding de uma palavra a ser medido.\n","    `embeddingsWj` - Um embedding de uma palavra a ser medido.\n","  \"\"\"\n"," \n","  #print(\"embeddingWi=\", embeddingWi.shape) \n","  #print(\"embeddingWj=\", embeddingWj.shape)\n","\n","  # Similaridade do cosseno entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  cos = similaridadeCosseno(embeddingWi, embeddingWj)\n","  # Saída: Número real\n","\n","  # Distância euclidiana entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  euc = distanciaEuclidiana(embeddingWi, embeddingWj)\n","  # Saída: Número real\n","\n","  # Distância de manhattan entre os embeddings wi e wj\n","  # Entrada: (<768 ou 1024>) x (<768 ou 1024>)\n","  man = distanciaManhattan(embeddingWi, embeddingWj)\n","  # Saída: Número real\n","\n","  del embeddingWi\n","  del embeddingWj\n","   \n","  # Retorno das medidas das sentenças\n","  return cos, euc, man"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KEtmDaKqAL-9"},"source":["### 5.2.4 getTokensEmbeddingsPOSSentenca\n","Gera os tokens, POS e embeddings de cada sentença."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXPWq5JyIoQf"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar mais tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera mais tokens que a tokenização das palavras do spaCy\n","dic_excecao_maior = {\"\":-1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89oBywgbIxzV"},"outputs":[],"source":["def getExcecaoDicMaior(id, token, dic_excecao_maior):   \n","    \n","  valor = dic_excecao_maior.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPODj-AWfhxW"},"outputs":[],"source":["# Dicionário de tokens de exceções e seus deslocamentos para considerar menos tokens do BERT em relação ao spaCy\n","# A tokenização do BERT gera menos tokens que a tokenização das palavras do spaCy\n","dic_excecao_menor = {\"1°\":1,\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xy2bzLBWfeqi"},"outputs":[],"source":["def getExcecaoDicMenor(id, token, dic_excecao_menor):   \n","    \n","  valor = dic_excecao_menor.get(token)\n","  if valor != None:\n","      return valor\n","  else:\n","      return -1"]},{"cell_type":"markdown","source":["Função que retorna os embeddings, tokens e POS da sentença com um mesmo tamanho."],"metadata":{"id":"LLRdNsbo0qxA"}},{"cell_type":"code","source":["# Importa a biblioteca\n","import torch\n","\n","def getTokensEmbeddingsPOSSentenca(id_documento, \n","                                   indexsentenca, \n","                                   embeddingDocumento, \n","                                   tokenBERTDocumento, \n","                                   sentenca, \n","                                   tokenizer, \n","                                   sentenca_token = None, \n","                                   sentenca_pos = None, \n","                                   estrategia_medida = 0):\n","    \"\"\"    \n","      Retorna os tokens, as postagging e os embeddings dos tokens igualando a quantidade de tokens do spaCy com a tokenização do BERT de acordo com a estratégia. \n","      Usa a estratégia MEAN para calcular a média dos embeddings dos tokens que formam uma palavra.\n","      Usa a estratégia MAX para calcular o valor máximo dos embeddings dos tokens que formam uma palavra.\n","    \"\"\"\n","   \n","    #Guarda os tokens e embeddings\n","    listaTokens = []\n","    listaEmbeddings = []\n","\n","    if sentenca_token == None:\n","      # Gera a tokenização e POS-Tagging da sentença    \n","      sentenca_token, sentenca_pos = getListaTokensPOSSentenca(sentenca)\n","\n","    #print(\"\\nsentenca            :\",sentenca)    \n","    #print(\"id_documento        :\",id_documento)\n","    #print(\"indexsentenca       :\",indexsentenca)    \n","    #print(\"sentenca_token      :\",sentenca_token)\n","    #print(\"len(sentenca_token) :\",len(sentenca_token))    \n","    #print(\"sentenca_pos        :\",sentenca_pos)\n","    #print(\"len(sentenca_pos)   :\",len(sentenca_pos))\n","    \n","    # Recupera os embeddings da sentença dos embeddings do documento    \n","    embeddingSentenca, sentencaTokenizadaBert = getEmbeddingSentencaEmbeddingDocumentoComTodasPalavras(embeddingDocumento, \n","                                                                                                       tokenBERTDocumento, \n","                                                                                                       sentenca, \n","                                                                                                       tokenizer)\n","    \n","    # embedding <qtde_tokens x 4096>        \n","    #print(\"embeddingSentenca          :\",embeddingSentenca.shape)\n","    #print(\"sentencaTokenizadaBert     :\",sentencaTokenizadaBert)\n","    #print(\"len(sentencaTokenizadaBert):\",len(sentencaTokenizadaBert))\n","\n","    # Seleciona os pares de palavra a serem avaliadas\n","    posWi = 0 # Posição do token da palavra gerado pelo spaCy\n","    posWj = posWi # Posição do token da palavra gerado pelo BERT\n","\n","    # Enquanto o indíce da palavra posWj(2a palavra) não chegou ao final da quantidade de tokens do BERT\n","    while posWj < len(sentencaTokenizadaBert):  \n","\n","      # Seleciona os tokens da sentença\n","      Wi = sentenca_token[posWi] # Recupera o token da palavra gerado pelo spaCy\n","      Wi1 = \"\"\n","      if posWi+1 < len(sentenca_token):\n","        Wi1 = sentenca_token[posWi+1] # Recupera o próximo token da palavra gerado pelo spaCy\n","  \n","        # Localiza o deslocamento da exceção\n","        #pos = getExcecao(Wi,lista_excecao,lista_deslocamento)\n","        pos2 = getExcecaoDicMenor(id_documento, Wi+Wi1, dic_excecao_menor)  \n","        #print(\"Exceção pos2:\", pos2)\n","\n","      Wj = sentencaTokenizadaBert[posWj] # Recupera o token da palavra gerado pelo BERT\n","      #print(\"Wi[\",posWi,\"]=\", Wi)\n","      #print(\"Wj[\",posWj,\"]=\", Wj)\n","\n","      # Tratando exceções\n","      # Localiza o deslocamento da exceção\n","      #pos = getExcecao(Wi,lista_excecao,lista_deslocamento)\n","      pos = getExcecaoDicMaior(id_documento, Wi, dic_excecao_maior)  \n","      #print(\"Exceção pos:\", pos)\n","            \n","      if pos != -1 or pos2 != -1:      \n","        if pos != -1:\n","          #print(\"Adiciona 1 Exceção palavra == Wi or palavra = [UNK]:\",Wi)\n","          listaTokens.append(Wi)          \n","          # Verifica se tem mais de um token\n","          if pos != 1:\n","            indiceToken = posWj + pos\n","            #print(\"Calcula a média de :\", posWj , \"até\", indiceToken)\n","            embeddingsTokensPalavra = embeddingSentenca[posWj:indiceToken]\n","            #print(\"embeddingsTokensPalavra:\",embeddingsTokensPalavra.shape)\n","            # calcular a média dos embeddings dos tokens do BERT da palavra\n","            embeddingMedia = torch.mean(embeddingsTokensPalavra, dim=0)\n","            #print(\"embeddingMedia:\",embeddingMedia.shape)\n","            listaEmbeddings.append(embeddingMedia)\n","          else:\n","            # Adiciona o embedding do token a lista de embeddings\n","            listaEmbeddings.append(embeddingSentenca[posWj])\n","         \n","          # Avança para a próxima palavra e token do BERT\n","          posWi = posWi + 1\n","          posWj = posWj + pos\n","          #print(\"Proxima:\")            \n","          #print(\"Wi[\",posWi,\"]=\", sentenca_token[posWi])\n","          #print(\"Wj[\",posWj,\"]=\", sentencaTokenizadaBert[posWj])\n","        else:\n","          if pos2 != -1:\n","            #print(\"Adiciona 1 Exceção palavra == Wi or palavra = [UNK]:\",Wi)\n","            listaTokens.append(Wi+Wi1)          \n","            # Verifica se tem mais de um token\n","            if pos2 == 1: \n","              # Adiciona o embedding do token a lista de embeddings\n","              listaEmbeddings.append(embeddingSentenca[posWj])\n","          \n","            # Avança para a próxima palavra e token do BERT\n","            posWi = posWi + 2\n","            posWj = posWj + pos2\n","            #print(\"Proxima:\")            \n","            #print(\"Wi[\",posWi,\"]=\", sentenca_token[posWi])\n","            #print(\"Wj[\",posWj,\"]=\", sentencaTokenizadaBert[posWj])\n","      else:  \n","        # Tokens iguais adiciona a lista, o token não possui subtoken\n","        if (Wi == Wj or Wj==\"[UNK]\"):\n","          # Adiciona o token a lista de tokens\n","          #print(\"Adiciona 2 Wi==Wj or Wj==[UNK]:\", Wi )\n","          listaTokens.append(Wi)          \n","          # Adiciona o embedding do token a lista de embeddings\n","          listaEmbeddings.append(embeddingSentenca[posWj])\n","          #print(\"embedding1[posWj]:\", embeddingSentenca[posWj].shape)\n","          # Avança para a próxima palavra e token do BERT\n","          posWi = posWi + 1\n","          posWj = posWj + 1   \n","              \n","        else:          \n","          # A palavra foi tokenizada pelo Wordpice com ## ou diferente do spaCy ou desconhecida\n","          # Inicializa a palavra a ser montada          \n","          palavraPOS = Wj\n","          indiceToken = posWj + 1                 \n","          while  ((palavraPOS != Wi) and indiceToken < len(sentencaTokenizadaBert)):\n","              if \"##\" in sentencaTokenizadaBert[indiceToken]:\n","                # Remove os caracteres \"##\" do token\n","                parte = sentencaTokenizadaBert[indiceToken][2:]\n","              else:                \n","                parte = sentencaTokenizadaBert[indiceToken]\n","              \n","              palavraPOS = palavraPOS + parte\n","              #print(\"palavraPOS:\",palavraPOS)\n","              # Avança para o próximo token do BERT\n","              indiceToken = indiceToken + 1\n","\n","          #print(\"\\nMontei palavra:\",palavraPOS)\n","          if (palavraPOS == Wi or palavraPOS == \"[UNK]\"):\n","              # Adiciona o token a lista\n","              #print(\"Adiciona 3 palavra == Wi or palavraPOS = [UNK]:\",Wi)\n","              listaTokens.append(Wi)\n","              # Calcula a média dos tokens da palavra\n","              #print(\"Calcula o máximo :\", posWj , \"até\", indiceToken)\n","              embeddingsTokensPalavra = embeddingSentenca[posWj:indiceToken]\n","              #print(\"embeddingsTokensPalavra2:\",embeddingsTokensPalavra)\n","              #print(\"embeddingsTokensPalavra2:\",embeddingsTokensPalavra.shape)\n","\n","              # Calcula a média ou máximo dos embeddings das palavras de acordo com a estratégia de pooling dos embeddings\n","              if estrategia_medida == 0:\n","                # calcular a média dos embeddings dos tokens do BERT da palavra\n","                embeddingEstrategia = torch.mean(embeddingsTokensPalavra, dim=0)              \n","              else:\n","                # calcular o valor máximo dos embeddings dos tokens do BERT da palavra\n","                embeddingEstrategia, linha = torch.max(embeddingsTokensPalavra, dim=0)\n","              \n","              #print(\"embeddingEstrategia:\",embeddingEstrategia)\n","              #print(\"embeddingEstrategia.shape:\",embeddingEstrategia.shape)\n","              listaEmbeddings.append(embeddingEstrategia)\n","\n","          # Avança para o próximo token do spaCy\n","          posWi = posWi + 1\n","          # Pula para o próximo token do BERT\n","          posWj = indiceToken\n","    \n","    # Verificação se as listas estão com o mesmo tamanho\n","    #if (len(listaTokens) != len(sentenca_token)) or (len(listaEmbeddings) != len(sentenca_token)):\n","    if (len(listaTokens) !=  len(listaEmbeddings)):\n","       print(\"\\nsentenca                :\",sentenca)  \n","       print(\"id_documento            :\",id_documento)     \n","       print(\"indexsentenca           :\",indexsentenca)\n","       print(\"sentenca_pos            :\",sentenca_pos)\n","       print(\"sentenca_token          :\",sentenca_token)\n","       print(\"sentencaTokenizadaBert  :\",sentencaTokenizadaBert)\n","       print(\"listaTokens             :\",listaTokens)        \n","       print(\"len(listaTokens)        :\",len(listaTokens))       \n","       print(\"listaEmbeddings         :\",listaEmbeddings)\n","       print(\"len(listaEmbeddings)    :\",len(listaEmbeddings))\n","\n","    del embeddingSentenca\n","    del tokenBERTDocumento\n","    del tokenizer\n","\n","    return listaTokens, sentenca_pos, listaEmbeddings"],"metadata":{"id":"rhqh2qFd4pIv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kw0qQ6zoQhkq"},"source":["### 5.2.5 comparaPalavrasSentencaTodas"]},{"cell_type":"code","metadata":{"id":"Of3EOJwpQg-B"},"source":["def comparaPalavrasSentencaTodas(id_documento, \n","                                 indexdocumento, \n","                                 indexsentenca, \n","                                 embeddingDocumento, \n","                                 tokenBERTDocumento, \n","                                 sentenca, \n","                                 tokenizer, \n","                                 sentenca_token = None, \n","                                 sentenca_pos = None):\n","\n","  listaTokens, listaPOS, listaEmbeddings = getTokensEmbeddingsPOSSentenca(id_documento, \n","                                                                          indexsentenca, \n","                                                                          embeddingDocumento, \n","                                                                          tokenBERTDocumento, \n","                                                                          sentenca, \n","                                                                          tokenizer, \n","                                                                          sentenca_token, \n","                                                                          sentenca_pos)  \n","  #print(\"\\nSentença   :\",listaTokens)\n","  #print(\"POS Tagging:\",listaPOS)\n","  #print(\"Quantidade de palavras:\",len(listaTokens))\n","\n","  # Quantidade de palavras no documento\n","  n = len(listaTokens)\n","  \n","  # Guarda a comparação da sentença\n","  lista_comparacao = []\n"," \n","  # Realiza o combinação das palavras C(n,p)=(n!/(p!(n-p)!))\n","  # n = Número de elementos e p as combinações\n","  # C(5,2) = 10\n","  # Percorre as palavras da sentença\n","  for i in range(0,n-1):\n","  #for i in range(n):\n","    # Seleciona a palavra i da sentença\n","    wi = listaTokens[i]\n","    posi = listaPOS[i]\n","    #print(\"i:\",i)\n","    # Percorre as palavras da sentença\n","    for j in range(i+1,n):\n","    #for j in range(n):                                \n","      # Para não comparar a palavra com ela mesma\n","      #if i != j:\n","        # Seleciona a palavra j da sentença\n","        wj = listaTokens[j]\n","        posj = listaPOS[j]\n","        \n","        # Recupera as medidas dos embeddings das palavras\n","        cos, euc, man = getMedidasEmbedding(listaEmbeddings[i], listaEmbeddings[j])\n","\n","        # Agrupa as medidas e guarda na lista\n","        comparacao = [id_documento, indexdocumento, indexsentenca, str(wi), posi, str(wj), posj, cos, euc, man]\n","        lista_comparacao.append(comparacao)\n","\n","        #print(comparacao)\n","        # print(\"Compara :\", i, \" com \", j)\n","        #print(\"Compara :\", wi, \" com \", wj)\n","        # print(\"     cos:\", cos)\n","        # print(\"     euc:\", euc)\n","        # print(\"     man:\", man)\n","  \n","  return lista_comparacao"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXNhBApgbULb"},"source":["### 5.2.6 Realiza a comparação de todas as palavras dos documentos"]},{"cell_type":"code","metadata":{"id":"CfGFsRaPDBMt","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["35a4c444a1154e11953b59e989f05b99","4b27342020ed4735b03414689b74c5f7","b6212d07aeb94cd38dc66486fd8385d5","f49820b508544287aff69e4a190576c2","e8d7cd36564b48af9b07bec63555affd","9379761406fb48ffb2b3243170551076","d01a9ffc4e434c86ad4c15a0abff57d8","8981f1d005894e07a08a939fb8e8d359","377ce39479584fceaef05add9f6b2b9d","1ef3c3c2912242e59a57590b9214f1ce","97e68fe0744c4b55a92c4ba8bbce6d41"]},"executionInfo":{"status":"ok","timestamp":1646828624725,"user_tz":180,"elapsed":54021,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"ccf6f2aa-19b5-4fc2-ac1d-c680edbff9d3"},"source":["# Import das bibliotecas\n","from tqdm.notebook import tqdm as tqdm_notebook\n","\n","logging.info(\"Processando {} documentos originais.\".format(len(lista_documentos_originais)))\n","\n","# Guarda a comparacação das sentenças\n","resultado_comparacao = []\n","\n","# Conta sentenças comparadas e não comparadas\n","contaSentenca = 0\n","\n","# Barra de progresso dos documentos\n","lista_documentos_bar = tqdm_notebook(lista_documentos_originais.iterrows(), desc=f\"Documentos\", unit=f\" documento\", total=len(lista_documentos_originais))\n","\n","# Percorre os documentos\n","for i, linha_documento in lista_documentos_bar:  \n","  #if i <  5:     \n","    #print(\"linha_documento:\",linha_documento)\n","    # Recupera o id do documento\n","    id_documento = linha_documento[0]     \n","    #print(\"id_documento:\",id_documento)    \n","    # Recupera o documento \n","    documento = linha_documento[2]\n","    #print(\"documento:\",documento) \n","    \n","    # Carrega as listas das sentenças e postagging dos documento    \n","    lista_sentenca_documento = linha_documento[1]\n","    # Localiza a POSTagging do documento\n","    lista_pos_documento = lista_documentos_originais_pos.iloc[i][1]\n","    #print(\"lista_sentenca_documento:\",lista_sentenca_documento)\n","    #print(\"len(lista_sentenca_documento):\",len(lista_sentenca_documento))\n","    #print(\"lista_pos_documento:\",lista_pos_documento)\n","    #print(\"len(lista_pos_documento):\",len(lista_pos_documento))\n","        \n","    # Verifica se é necessário utilizar janelas de documentos \n","    if model_args.janela != 0:\n","      # Recupera os n documentos antes e depois do documento para formar a janela\n","      lista_Janela_documento, string_janela_documento =  getJanelaSentenca(lista_documentos_originais, \n","                                                                          model_args.janela, \n","                                                                          i)\n","      # Submete o documento e a janela de documentos ao BERT para recuperar os embeddings do documento\n","      # Gera os embeddings do documento utiliza a concatenação das 4 últimas camadas\n","      embeddingDocumento, tokenBERTDocumento = getEmbeddingsConcat4UltimasCamadasJanela(documento, \n","                                                                                          string_janela_documento,\n","                                                                                          model,                                                                                          \n","                                                                                          tokenizer)      \n","                \n","    else:\n","      # Gera os embeddings do documento utiliza a concatenação das 4 últimas camadas sem janela\n","      embeddingDocumento, tokenBERTDocumento = getEmbeddingsConcat4UltimasCamadas(documento, \n","                                                                                    model, \n","                                                                                    tokenizer)  \n","      \n","    # embedding <qtde_tokens x 4096>                \n","    #print(\"embeddingDocumento:\",embeddingDocumento.shape)\n","    #print(\"tokenBERTDocumento:\",tokenBERTDocumento)\n","    #print(\"len(tokenBERTDocumento):\",len(tokenBERTDocumento))\n","                                             \n","    # Percorre as sentenças do documento\n","    for j, sentenca in enumerate(lista_sentenca_documento):      \n","      #print(\"id_documento:\",id_documento)\n","      #print(\"sentenca:\",sentenca)\n","\n","      # Carrega as POSTagging da sentença\n","      sentenca_token = lista_pos_documento[j][0]\n","      sentenca_pos = lista_pos_documento[j][1]\n","      sentenca_verbos = lista_pos_documento[j][2]\n","      \n","      #print(\"sentenca_token:\",sentenca_token)\n","      #print(\"len(sentenca_token):\",len(sentenca_token))\n","\n","      #print(\"sentenca_pos:\",sentenca_pos)\n","      #print(\"len(sentenca_pos):\",len(sentenca_pos))\n","\n","      #print(\"sentenca_verbos:\",sentenca_verbos)\n","      #print(\"len(sentenca_verbos):\",len(sentenca_verbos))\n","\n","      # Conta o número de sentenças com palavras comparadas\n","      contaSentenca = contaSentenca + 1\n","\n","      # Recupera as maiores e menores medidas entre as palavras\n","      lista_comparacao = comparaPalavrasSentencaTodas(id_documento, \n","                                                      i, \n","                                                      j, \n","                                                      embeddingDocumento, \n","                                                      tokenBERTDocumento, \n","                                                      sentenca, \n","                                                      tokenizer, \n","                                                      sentenca_token, \n","                                                      sentenca_pos)\n","      #print(len(lista_comparacao))\n","      #print(lista_comparacao)\n","\n","      # Guarda o resultado da comparação\n","      resultado_comparacao = resultado_comparacao + lista_comparacao"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:22:50,349 : INFO : Processando 40 documentos originais.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35a4c444a1154e11953b59e989f05b99","version_minor":0,"version_major":2},"text/plain":["Documentos:   0%|          | 0/40 [00:00<?, ? documento/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ugwTe8C3ebjy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828624725,"user_tz":180,"elapsed":39,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"e8a8c096-e979-4948-e224-259d17cb7e1f"},"source":["#logging.info(\"Número de sentenças com palavras comparadas: {}.\".format(contaSentenca))\n","logging.info(\"Número de comparações                      : {}.\".format(len(resultado_comparacao)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:23:44,275 : INFO : Número de comparações                      : 2240.\n"]}]},{"cell_type":"markdown","metadata":{"id":"rMg19DZzYjHB"},"source":["## 5.3 Gera arquivo das comparações"]},{"cell_type":"markdown","metadata":{"id":"FgUGrLmKCO84"},"source":["### 5.3.1 Especifica os nomes dos arquivos de dados\n","\n"]},{"cell_type":"code","metadata":{"id":"kahGlJdWdP8f"},"source":["# Nome do arquivo\n","NOMEARQUIVOCOMPARACAO = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".csv\"\n","NOMEARQUIVOCOMPARACAOCOMPACTADO = \"comparacao_palavra_p\" + str(model_args.documentos_perturbados) + \"_k\" + str(model_args.top_k_predicao) + \".zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"midCJ2AYes2x"},"source":["### 5.3.2 Gera arquivo comparação"]},{"cell_type":"code","metadata":{"id":"vdHTuPLDYjHB"},"source":["# Import das bibliotecas.\n","import pandas as pd\n","\n","# Cria o dataframe da lista\n","dfresultado_comparacao = pd.DataFrame(resultado_comparacao, columns = [\"id_documento\", \"indexdocumento\",\"indexsentenca\", \"wi\", \"posi\",\"wj\",\"posj\", \"cos\", \"euc\",\"man\"])\n","\n","# Nome do arquivo original\n","nomeArquivo = DIRETORIO_LOCAL + NOMEARQUIVOCOMPARACAO\n","\n","# Salva o arquivo original\n","dfresultado_comparacao.to_csv(nomeArquivo,  sep=\";\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9JSH-_lYjHB"},"source":["### 5.3.3 Carrega os dados\n","\n","Carrega os dados das sentencas a partir dos arquivos.\n"]},{"cell_type":"code","metadata":{"id":"9ob-mUkjYjHC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828624727,"user_tz":180,"elapsed":30,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"4ca37f90-20e3-4764-ac03-cba7a1ab919b"},"source":["# Importa das bibliotecas.\n","import pandas as pd\n","\n","# Abre o arquivo e retorna o DataFrame\n","dresultado_comparacao = pd.read_csv(DIRETORIO_LOCAL + NOMEARQUIVOCOMPARACAO, sep=\";\", encoding=\"UTF-8\")\n","\n","logging.info(\"Quantidade de comparações: {}.\".format(len(dresultado_comparacao)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:23:44,372 : INFO : Quantidade de comparações: 2240.\n"]}]},{"cell_type":"code","metadata":{"id":"vNCI53tPYjHC","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"ok","timestamp":1646828624727,"user_tz":180,"elapsed":24,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"845bdb7d-3d92-4581-a0cf-bc07b961b547"},"source":["dresultado_comparacao.sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-240d1784-0f6e-4b71-97b0-ccdb5d686be9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_documento</th>\n","      <th>indexdocumento</th>\n","      <th>indexsentenca</th>\n","      <th>wi</th>\n","      <th>posi</th>\n","      <th>wj</th>\n","      <th>posj</th>\n","      <th>cos</th>\n","      <th>euc</th>\n","      <th>man</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1613</th>\n","      <td>33</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>Como</td>\n","      <td>ADV</td>\n","      <td>implementadas</td>\n","      <td>VERB</td>\n","      <td>0.511271</td>\n","      <td>39.849865</td>\n","      <td>1865.1534</td>\n","    </tr>\n","    <tr>\n","      <th>666</th>\n","      <td>19</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>O</td>\n","      <td>PRON</td>\n","      <td>e</td>\n","      <td>CCONJ</td>\n","      <td>0.539752</td>\n","      <td>41.447109</td>\n","      <td>2079.2085</td>\n","    </tr>\n","    <tr>\n","      <th>2194</th>\n","      <td>40</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>uma</td>\n","      <td>DET</td>\n","      <td>?</td>\n","      <td>PUNCT</td>\n","      <td>0.553896</td>\n","      <td>38.102005</td>\n","      <td>1896.1267</td>\n","    </tr>\n","    <tr>\n","      <th>431</th>\n","      <td>13</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>elementos</td>\n","      <td>NOUN</td>\n","      <td>em</td>\n","      <td>ADP</td>\n","      <td>0.549378</td>\n","      <td>40.671204</td>\n","      <td>1869.5812</td>\n","    </tr>\n","    <tr>\n","      <th>1122</th>\n","      <td>26</td>\n","      <td>25</td>\n","      <td>0</td>\n","      <td>que</td>\n","      <td>PRON</td>\n","      <td>?</td>\n","      <td>PUNCT</td>\n","      <td>0.485957</td>\n","      <td>43.765354</td>\n","      <td>2185.5225</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-240d1784-0f6e-4b71-97b0-ccdb5d686be9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-240d1784-0f6e-4b71-97b0-ccdb5d686be9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-240d1784-0f6e-4b71-97b0-ccdb5d686be9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      id_documento  indexdocumento  indexsentenca         wi  posi  \\\n","1613            33              32              0       Como   ADV   \n","666             19              18              0          O  PRON   \n","2194            40              39              0        uma   DET   \n","431             13              12              0  elementos  NOUN   \n","1122            26              25              0        que  PRON   \n","\n","                 wj   posj       cos        euc        man  \n","1613  implementadas   VERB  0.511271  39.849865  1865.1534  \n","666               e  CCONJ  0.539752  41.447109  2079.2085  \n","2194              ?  PUNCT  0.553896  38.102005  1896.1267  \n","431              em    ADP  0.549378  40.671204  1869.5812  \n","1122              ?  PUNCT  0.485957  43.765354  2185.5225  "]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","metadata":{"id":"DFMUo8Oo2CJp"},"source":["### 5.4.4 Compacta e copia o arquivo para uma pasta do GoogleDrive\n","\n","Compacta o arquivo gerado da comparação para facilitar o envio para o GoogleDrive"]},{"cell_type":"markdown","metadata":{"id":"7eb_zukpuHq3"},"source":["Compacta o arquivo.\n","\n","Usa o zip para compactar:\n","*   `-o` sobrescreve o arquivo se existir\n","*   `-j` Não cria nenhum diretório\n","*   `-q` Desliga as mensagens "]},{"cell_type":"code","metadata":{"id":"NunMOJWR2O8H"},"source":["!zip -o -j -q \"$DIRETORIO_LOCAL$NOMEARQUIVOCOMPARACAOCOMPACTADO\" \"$DIRETORIO_LOCAL$NOMEARQUIVOCOMPARACAO\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"49_9c2P2nrOx"},"source":["Copia o arquivo  para o GoogleDrive"]},{"cell_type":"code","metadata":{"id":"LqDBH5pUnrOx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828625283,"user_tz":180,"elapsed":21,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"6fd23907-56d0-4588-f489-627fbc63cff2"},"source":["# Se estiver executando no Google Colaboratory\n","if IN_COLAB:\n","   \n","    # Copia o arquivo das comparações para o google drive\n","    #!cp \"$DIRETORIO_LOCAL$NOMEARQUIVOCOMPARACAOCOMPACTADO\" \"$DIRETORIO_DRIVE\"\n","    \n","    logging.info(\"Terminei a cópia do arquivo.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-09 12:23:44,718 : INFO : Terminei a cópia do arquivo.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yj0ya60zrm8t"},"source":["# 6 Finalização"]},{"cell_type":"markdown","metadata":{"id":"Bcjt085lZGUr"},"source":["## 6.1 Tempo final de processamento\n","\n"]},{"cell_type":"code","metadata":{"id":"H50_GKJwpDha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646828625284,"user_tz":180,"elapsed":15,"user":{"displayName":"Osmar Oliveira Braz Junior","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWOi4pjFUcxcAVbMlSKPe02ny7NFWEiEdI0Heo_k=s64","userId":"03010865824982624199"}},"outputId":"e1237527-cbc6-464a-f8a3-0ce1fe03a95c"},"source":["# Pega o tempo atual menos o tempo do início do processamento.\n","finalProcessamento = time.time()\n","tempoTotalProcessamento = formataTempo(finalProcessamento - inicioProcessamento)\n","\n","print(\"\")\n","print(\"  Tempo processamento:  {:} (h:mm:ss)\".format(tempoTotalProcessamento))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","  Tempo processamento:  0:06:12 (h:mm:ss)\n"]}]}]}